{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installazione delle Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: requests in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2024.6.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch==2.2.2 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.2+cpu)\n",
      "Requirement already satisfied: torchvision==0.17.2 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.17.2+cpu)\n",
      "Requirement already satisfied: torchaudio==2.2.2 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.2+cpu)\n",
      "Requirement already satisfied: filelock in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.2.2) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from torch==2.2.2) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.2.2) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.2.2) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.2.2) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch==2.2.2) (2024.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision==0.17.2) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision==0.17.2) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch==2.2.2) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch==2.2.2) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pytorch-tabnet in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: pytorch-tabular in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: tab-transformer-pytorch in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-tabnet) (1.26.4)\n",
      "Requirement already satisfied: scikit_learn>0.21 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-tabnet) (1.5.0)\n",
      "Requirement already satisfied: scipy>1.4 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-tabnet) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.3 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-tabnet) (2.2.2+cpu)\n",
      "Requirement already satisfied: tqdm>=4.36 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-tabnet) (4.66.4)\n",
      "Requirement already satisfied: pandas>=1.1.5 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-tabular) (2.2.2)\n",
      "Requirement already satisfied: pytorch-lightning<2.2.0,>=2.0.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-tabular) (2.1.4)\n",
      "Requirement already satisfied: omegaconf>=2.3.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-tabular) (2.3.0)\n",
      "Requirement already satisfied: torchmetrics<1.3.0,>=0.10.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-tabular) (1.2.1)\n",
      "Requirement already satisfied: tensorboard!=2.5.0,>2.2.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-tabular) (2.17.0)\n",
      "Requirement already satisfied: protobuf<4.26.0,>=3.20.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-tabular) (4.25.3)\n",
      "Requirement already satisfied: PyYAML<6.1.0,>=5.4 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-tabular) (6.0.1)\n",
      "Requirement already satisfied: matplotlib>3.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-tabular) (3.9.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-tabular) (8.1.3)\n",
      "Requirement already satisfied: einops<0.8.0,>=0.6.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-tabular) (0.7.0)\n",
      "Requirement already satisfied: rich>=11.0.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-tabular) (13.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>3.1->pytorch-tabular) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>3.1->pytorch-tabular) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>3.1->pytorch-tabular) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>3.1->pytorch-tabular) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>3.1->pytorch-tabular) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>3.1->pytorch-tabular) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib>3.1->pytorch-tabular) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib>3.1->pytorch-tabular) (2.9.0.post0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from omegaconf>=2.3.0->pytorch-tabular) (4.9.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.1.5->pytorch-tabular) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.1.5->pytorch-tabular) (2024.1)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch-tabular) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from pytorch-lightning<2.2.0,>=2.0.0->pytorch-tabular) (4.12.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch-lightning<2.2.0,>=2.0.0->pytorch-tabular) (0.11.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=11.0.0->pytorch-tabular) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from rich>=11.0.0->pytorch-tabular) (2.18.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (1.64.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (3.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (65.5.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (3.0.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.3->pytorch-tabnet) (3.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.36->pytorch-tabnet) (0.4.6)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets->pytorch-tabular) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets->pytorch-tabular) (8.25.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets->pytorch-tabular) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets->pytorch-tabular) (4.0.11)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipywidgets->pytorch-tabular) (3.0.11)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch-tabular) (3.9.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets->pytorch-tabular) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets->pytorch-tabular) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets->pytorch-tabular) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets->pytorch-tabular) (3.0.47)\n",
      "Requirement already satisfied: stack-data in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=6.1.0->ipywidgets->pytorch-tabular) (0.6.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.0.0->pytorch-tabular) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch-tabular) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch-tabular) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch-tabular) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch-tabular) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch-tabular) (1.9.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->pytorch-tabular) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->pytorch-tabular) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->pytorch-tabular) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->pytorch-tabular) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\gabriele\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->pytorch-tabular) (0.2.2)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch-tabular) (3.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas requests scikit-learn \n",
    "%pip install torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cpu\n",
    "%pip install -U pytorch-tabnet pytorch-tabular tab-transformer-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import e definizioni delle funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# import torch\n",
    "# from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "# from pytorch_tabular.models import TabTransformerModel\n",
    "# from pytorch_tabular.config import ModelConfig, DataConfig, TrainerConfig\n",
    "# from pytorch_tabular import TabularModel\n",
    "import pickle\n",
    "\n",
    "# Funzioni di utilit√†\n",
    "def save_model(model, directory, filename):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    with open(os.path.join(directory, filename + '.pkl'), 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "def cross_val_score_with_preprocessing(model, X, y, cv, scaler_type, use_pca, n_components):\n",
    "    mse_scores, mae_scores, r2_scores = [], [], []\n",
    "    for train_idx, val_idx in KFold(n_splits=cv, shuffle=True, random_state=89).split(X):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Scaling\n",
    "        if scaler_type == 'Standard':\n",
    "            scaler = StandardScaler().fit(X_train)\n",
    "        elif scaler_type == 'MinMax':\n",
    "            scaler = MinMaxScaler().fit(X_train)\n",
    "        X_train_scaled = scaler.transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "        # PCA\n",
    "        if use_pca:\n",
    "            pca = PCA(n_components=n_components).fit(X_train_scaled)\n",
    "            X_train_scaled = pca.transform(X_train_scaled)\n",
    "            X_val_scaled = pca.transform(X_val_scaled)\n",
    "        \n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_val_scaled)\n",
    "        mse_scores.append(mean_squared_error(y_val, y_pred))\n",
    "        mae_scores.append(mean_absolute_error(y_val, y_pred))\n",
    "        r2_scores.append(r2_score(y_val, y_pred))\n",
    "        \n",
    "    return np.mean(mse_scores), np.mean(mae_scores), np.mean(r2_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_state = 89\n",
    "\n",
    "# def save_model(model, directory, filename):\n",
    "#     if not os.path.exists(directory):\n",
    "#         os.makedirs(directory)\n",
    "#     joblib.dump(model, os.path.join(directory, f'{filename}.pkl'))\n",
    "\n",
    "# def preprocess(X, scaler_type='standard', use_pca=False, n_components=None):\n",
    "#     if scaler_type == 'standard':\n",
    "#         scaler = StandardScaler()\n",
    "#     elif scaler_type == 'minmax':\n",
    "#         scaler = MinMaxScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#     pca = None\n",
    "#     if use_pca and n_components:\n",
    "#         pca = PCA(n_components=n_components, random_state=random_state)\n",
    "#         X_scaled = pca.fit_transform(X_scaled)\n",
    "\n",
    "#     return X_scaled, scaler, pca\n",
    "\n",
    "# def cross_val_score_with_preprocessing(model, X, y, cv=5, scaler_type='standard', use_pca=False, n_components=None):\n",
    "#     kf = KFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
    "#     mse_scores = []\n",
    "#     mae_scores = []\n",
    "#     r2_scores = []\n",
    "\n",
    "#     for train_index, test_index in kf.split(X):\n",
    "#         X_train, X_test = X[train_index], X[test_index]\n",
    "#         y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "#         X_train_scaled, scaler, pca = preprocess(X_train, scaler_type=scaler_type, use_pca=use_pca, n_components=n_components)\n",
    "#         X_test_scaled = scaler.transform(X_test)\n",
    "#         if pca:\n",
    "#             X_test_scaled = pca.transform(X_test_scaled)\n",
    "\n",
    "#         model.fit(X_train_scaled, y_train)\n",
    "#         y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "#         mse_scores.append(mean_squared_error(y_test, y_pred))\n",
    "#         mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "#         r2_scores.append(r2_score(y_test, y_pred))\n",
    "\n",
    "#     return np.mean(mse_scores), np.mean(mae_scores), np.mean(r2_scores)\n",
    "\n",
    "\n",
    "\n",
    "# def grid_search_cv_with_preprocessing(model, param_grid, X, y, cv=5, scaler_type='standard', use_pca=False, n_components=None):\n",
    "#     # Creazione del pipeline di preprocessing\n",
    "#     steps = []\n",
    "#     if scaler_type == 'standard':\n",
    "#         steps.append(('scaler', StandardScaler()))\n",
    "#     elif scaler_type == 'minmax':\n",
    "#         steps.append(('scaler', MinMaxScaler()))\n",
    "#     if use_pca:\n",
    "#         steps.append(('pca', PCA(n_components=n_components)))\n",
    "\n",
    "#     pipeline = Pipeline(steps + [('model', model)])\n",
    "    \n",
    "#     # Grid Search CV\n",
    "#     grid_search = GridSearchCV(pipeline, param_grid, cv=cv, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "#     grid_search.fit(X, y)\n",
    "    \n",
    "#     best_model = grid_search.best_estimator_\n",
    "#     best_params = grid_search.best_params_\n",
    "#     best_score = -grid_search.best_score_\n",
    "    \n",
    "#     return best_model, best_params, best_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def save_performance(model_name, scaler_type, use_pca, mse, mae, r2, mse_cv, mae_cv, r2_cv, filename='model_performance.csv'):\n",
    "#     file_exists = os.path.isfile(filename)\n",
    "#     with open(filename, mode='a', newline='') as file:\n",
    "#         writer = csv.writer(file)\n",
    "#         if not file_exists:\n",
    "#             writer.writerow(['Model', 'Scaler', 'PCA', 'MSE', 'MAE', 'R2', 'CV_MSE', 'CV_MAE', 'CV_R2'])\n",
    "#         writer.writerow([model_name, scaler_type, use_pca, mse, mae, r2, mse_cv, mae_cv, r2_cv])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caricamento dei Dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurazione dei modelli\n",
    "preprocessing_options = {\n",
    "    'LR': {'scaler_type': ['Standard', 'MinMax'], 'use_pca': [True, False]},\n",
    "    'RF': {'scaler_type': ['Standard', 'MinMax'], 'use_pca': [True, False]},\n",
    "    'KNR': {'scaler_type': ['Standard', 'MinMax'], 'use_pca': [True, False]},\n",
    "    'SVR': {'scaler_type': ['Standard', 'MinMax'], 'use_pca': [True, False]},\n",
    "    'FFNN': {'scaler_type': ['Standard', 'MinMax'], 'use_pca': [True, False]},\n",
    "    'TabNet': {'scaler_type': ['Standard', 'MinMax'], 'use_pca': [False]},\n",
    "    'TabTransformer': {'scaler_type': ['Standard', 'MinMax'], 'use_pca': [False]}\n",
    "}\n",
    "\n",
    "# CSV zip folder's path\n",
    "csv_file_name = '../data.zip'\n",
    "# loading data from csv\n",
    "df = pd.read_csv(csv_file_name)\n",
    "\n",
    "X = df.drop('Year', axis=1)\n",
    "y = df['Year']\n",
    "\n",
    "# Divisione in training e validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=89)\n",
    "\n",
    "# Creazione degli scaler e PCA per ogni combinazione di preprocessing\n",
    "scalers = {}\n",
    "pcas = {}\n",
    "\n",
    "for model in preprocessing_options:\n",
    "    for scaler_type in preprocessing_options[model]['scaler_type']:\n",
    "        for use_pca in preprocessing_options[model]['use_pca']:\n",
    "            key = f\"{model}_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "            if scaler_type == 'Standard':\n",
    "                scaler = StandardScaler().fit(X_train)\n",
    "            elif scaler_type == 'MinMax':\n",
    "                scaler = MinMaxScaler().fit(X_train)\n",
    "            scalers[key] = scaler\n",
    "            if use_pca:\n",
    "                pca = PCA(n_components=52).fit(scaler.transform(X_train))\n",
    "                pcas[key] = pca\n",
    "            else:\n",
    "                pcas[key] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funzioni di Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per addestrare i modelli\n",
    "def train_model(X_train_scaled, y_train, model_type):\n",
    "    if model_type == 'LR':\n",
    "        model = LinearRegression()\n",
    "    elif model_type == 'RF':\n",
    "        model = RandomForestRegressor(random_state=89)\n",
    "    elif model_type == 'KNR':\n",
    "        model = KNeighborsRegressor()\n",
    "    elif model_type == 'SVR':\n",
    "        model = SVR()\n",
    "    return model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Funzione per addestrare una rete neurale feed-forward\n",
    "def train_ffnn(X_train_scaled, y_train, input_dim):\n",
    "    class FFNN(torch.nn.Module):\n",
    "        def __init__(self, input_dim):\n",
    "            super(FFNN, self).__init__()\n",
    "            self.fc1 = torch.nn.Linear(input_dim, 128)\n",
    "            self.fc2 = torch.nn.Linear(128, 64)\n",
    "            self.fc3 = torch.nn.Linear(64, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = torch.relu(self.fc1(x))\n",
    "            x = torch.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    ffnn = FFNN(input_dim=input_dim)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(ffnn.parameters(), lr=0.001)\n",
    "\n",
    "    X_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    ffnn.train()\n",
    "    for epoch in range(100):  # Adjust the number of epochs as needed\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ffnn(X_tensor)\n",
    "        loss = criterion(outputs, y_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return ffnn\n",
    "\n",
    "# Funzione per addestrare TabNet\n",
    "def train_tabnet(X_train_scaled, y_train, X_val_scaled, y_val):\n",
    "    tabnet = TabNetRegressor()\n",
    "    tabnet.fit(X_train_scaled, y_train, eval_set=[(X_val_scaled, y_val)], patience=10, max_epochs=100)\n",
    "    return tabnet\n",
    "\n",
    "# Funzione per addestrare TabTransformer\n",
    "def train_tabtransformer(df_train, df_val):\n",
    "    data_config = DataConfig(\n",
    "        target=['target_column'],\n",
    "        continuous_cols=df_train.columns.difference(['target_column']).tolist(),\n",
    "    )\n",
    "\n",
    "    model_config = ModelConfig(\n",
    "        task=\"regression\",\n",
    "        metrics=[\"mean_squared_error\", \"mean_absolute_error\", \"r2_score\"],\n",
    "        metrics_params=[{}, {}, {}]\n",
    "    )\n",
    "\n",
    "    trainer_config = TrainerConfig(\n",
    "        max_epochs=100,\n",
    "        gpus=0\n",
    "    )\n",
    "\n",
    "    tabular_model = TabularModel(\n",
    "        data_config=data_config,\n",
    "        model_config=model_config,\n",
    "        trainer_config=trainer_config\n",
    "    )\n",
    "\n",
    "    tabular_model.fit(train=df_train, validation=df_val)\n",
    "    return tabular_model\n",
    "\n",
    "# Preparazione del dizionario per salvare le performance\n",
    "performance_dict = {\n",
    "    'Model': [],\n",
    "    'Scaler': [],\n",
    "    'PCA': [],\n",
    "    'MSE_Val': [],\n",
    "    'MAE_Val': [],\n",
    "    'R2_Val': [],\n",
    "    'MSE_CV': [],\n",
    "    'MAE_CV': [],\n",
    "    'R2_CV': []\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing e salvataggio dei risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esegui il preprocessing specifico per ogni modello con Standard Scaler e Min-Max Scaler\n",
    "preprocessing_options = {\n",
    "    'LR': {'scaler_type': ['standard', 'minmax'], 'use_pca': [True, False], 'n_components': 52},\n",
    "    'RF': {'scaler_type': ['standard', 'minmax'], 'use_pca': [True, False], 'n_components': 52},\n",
    "    'KNR': {'scaler_type': ['standard', 'minmax'], 'use_pca': [True, False], 'n_components': 52},\n",
    "    'SVR': {'scaler_type': ['standard', 'minmax'], 'use_pca': [True, False], 'n_components': 52},\n",
    "    'FFNN': {'scaler_type': ['standard', 'minmax'], 'use_pca': [True, False], 'n_components': 52},\n",
    "    'TabNet': {'scaler_type': ['standard', 'minmax'], 'use_pca': [False], 'n_components': None},\n",
    "    'TabTransformer': {'scaler_type': ['standard', 'minmax'], 'use_pca': [False], 'n_components': None},\n",
    "}\n",
    "\n",
    "# Funzione per eseguire il preprocessing e salvare i risultati\n",
    "def preprocess_and_save(X_train, X_val, preprocessing_options):\n",
    "    scalers = {}\n",
    "    pcas = {}\n",
    "    for clfName, options in preprocessing_options.items():\n",
    "        for scaler_type in options['scaler_type']:\n",
    "            for use_pca in options['use_pca']:\n",
    "                key = f\"{clfName}_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "                X_train_scaled, scaler, pca = preprocess(X_train, scaler_type=scaler_type, use_pca=use_pca, n_components=options['n_components'])\n",
    "                X_val_scaled = scaler.transform(X_val)\n",
    "                if pca:\n",
    "                    X_val_scaled = pca.transform(X_val_scaled)\n",
    "                scalers[key] = scaler\n",
    "                pcas[key] = pca\n",
    "                directory = os.path.join('models', key.lower())\n",
    "                save_model(scaler, directory, 'scaler')\n",
    "                if pca:\n",
    "                    save_model(pca, directory, 'pca')\n",
    "    return scalers, pcas\n",
    "\n",
    "# Esegui il preprocessing per tutte le combinazioni di scaler e PCA\n",
    "scalers, pcas = preprocess_and_save(X_train, X_val, preprocessing_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training trad models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All the models (DO NOT run this cell if you don't want your PC to crash or to explode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestra i modelli tradizionali con tutte le combinazioni di scaler e PCA\n",
    "models = {}\n",
    "cv_performance = {}\n",
    "validation_performance = {}\n",
    "\n",
    "for clfName in ['LR', 'RF', 'KNR', 'SVR']:\n",
    "    for scaler_type in preprocessing_options[clfName]['scaler_type']:\n",
    "        for use_pca in preprocessing_options[clfName]['use_pca']:\n",
    "            key = f\"{clfName}_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "            X_train_scaled = scalers[key].transform(X_train)\n",
    "            if pcas[key]:\n",
    "                X_train_scaled = pcas[key].transform(X_train_scaled)\n",
    "            \n",
    "            model = train_model(X_train_scaled, y_train, model_type=clfName)\n",
    "            models[key] = model\n",
    "            save_model(model, f'model_{key.lower()}')\n",
    "\n",
    "            # Valutazione su validation set\n",
    "            X_val_scaled = scalers[key].transform(X_val)\n",
    "            if pcas[key]:\n",
    "                X_val_scaled = pcas[key].transform(X_val_scaled)\n",
    "            y_pred = model.predict(X_val_scaled)\n",
    "            mse = mean_squared_error(y_val, y_pred)\n",
    "            mae = mean_absolute_error(y_val, y_pred)\n",
    "            r2 = r2_score(y_val, y_pred)\n",
    "            validation_performance[key] = {'mse': mse, 'mae': mae, 'r2': r2}\n",
    "            print(f\"Validation Performance of {clfName} with {scaler_type} scaler and PCA={use_pca}: MSE={mse}, MAE={mae}, R2={r2}\")\n",
    "\n",
    "            # Cross-validation\n",
    "            mse_cv, mae_cv, r2_cv = cross_val_score_with_preprocessing(\n",
    "                model, X.values, y, cv=5, scaler_type=scaler_type, use_pca=use_pca, n_components=preprocessing_options[clfName]['n_components']\n",
    "            )\n",
    "            cv_performance[key] = {'mse': mse_cv, 'mae': mae_cv, 'r2': r2_cv}\n",
    "            print(f\"Cross-Validation Performance of {clfName} with {scaler_type} scaler and PCA={use_pca}: MSE={mse_cv}, MAE={mae_cv}, R2={r2_cv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "performance = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance of LR with Standard scaler and PCA: MSE=98.2318351539259, MAE=7.392438758148582, R2=0.12050186127982243\n",
      "Validation Performance of LR with Standard scaler and NoPCA: MSE=85.58234834475938, MAE=6.668881118801984, R2=0.23375638907108864\n",
      "Validation Performance of LR with MinMax scaler and PCA: MSE=87.21013510994777, MAE=6.73281651718109, R2=0.21918234158461758\n",
      "Validation Performance of LR with MinMax scaler and NoPCA: MSE=85.58234834475938, MAE=6.668881118801991, R2=0.23375638907108864\n"
     ]
    }
   ],
   "source": [
    "clfName = 'LR'\n",
    "for scaler_type in preprocessing_options[clfName]['scaler_type']:\n",
    "    for use_pca in preprocessing_options[clfName]['use_pca']:\n",
    "        key = f\"{clfName}_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "        X_train_scaled = scalers[key].transform(X_train)\n",
    "        if pcas[key]:\n",
    "            X_train_scaled = pcas[key].transform(X_train_scaled)\n",
    "\n",
    "        model = train_model(X_train_scaled, y_train, model_type=clfName)\n",
    "        directory = os.path.join('models', key.lower())\n",
    "        save_model(model, directory, 'model')\n",
    "\n",
    "        # Valutazione su validation set\n",
    "        X_val_scaled = scalers[key].transform(X_val)\n",
    "        if pcas[key]:\n",
    "            X_val_scaled = pcas[key].transform(X_val_scaled)\n",
    "        y_pred = model.predict(X_val_scaled)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        print(f\"Validation Performance of {clfName} with {scaler_type} scaler and {'PCA' if use_pca else 'NoPCA'}: MSE={mse}, MAE={mae}, R2={r2}\")\n",
    "\n",
    "        # Salvare le performance\n",
    "        performance_dict['Model'].append(clfName)\n",
    "        performance_dict['Scaler'].append(scaler_type)\n",
    "        performance_dict['PCA'].append(use_pca)\n",
    "        performance_dict['MSE_Val'].append(mse)\n",
    "        performance_dict['MAE_Val'].append(mae)\n",
    "        performance_dict['R2_Val'].append(r2)\n",
    "        performance_dict['MSE_CV'].append(None)  # No cross-validation for Linear Regression\n",
    "        performance_dict['MAE_CV'].append(None)\n",
    "        performance_dict['R2_CV'].append(None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance of RF with Standard scaler and PCA: MSE=92.01214625373923, MAE=7.210540541101935, R2=0.17618854169825393\n",
      "Cross-Validation Performance of RF with Standard scaler and PCA: MSE=90.85271300574892, MAE=7.169012839722981, R2=0.17553096742065438\n",
      "Validation Performance of RF with Standard scaler and NoPCA: MSE=79.40827703444918, MAE=6.436896507055287, R2=0.2890346419636943\n",
      "Cross-Validation Performance of RF with Standard scaler and NoPCA: MSE=78.4878556946283, MAE=6.400234070255443, R2=0.28774069750333975\n",
      "Validation Performance of RF with MinMax scaler and PCA: MSE=81.65413718735886, MAE=6.573940451406099, R2=0.26892680399838764\n",
      "Cross-Validation Performance of RF with MinMax scaler and PCA: MSE=80.79298888304402, MAE=6.526083350469959, R2=0.2668224632088366\n",
      "Validation Performance of RF with MinMax scaler and NoPCA: MSE=79.42058209449787, MAE=6.438306572816495, R2=0.28892447118868336\n",
      "Cross-Validation Performance of RF with MinMax scaler and NoPCA: MSE=78.52371315641918, MAE=6.401475427778328, R2=0.2874174746901928\n"
     ]
    }
   ],
   "source": [
    "clfName = 'RF'\n",
    "for scaler_type in preprocessing_options[clfName]['scaler_type']:\n",
    "    for use_pca in preprocessing_options[clfName]['use_pca']:\n",
    "        key = f\"{clfName}_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "        X_train_scaled = scalers[key].transform(X_train)\n",
    "        if pcas[key]:\n",
    "            X_train_scaled = pcas[key].transform(X_train_scaled)\n",
    "\n",
    "        model = train_model(X_train_scaled, y_train, model_type=clfName)\n",
    "        directory = os.path.join('models', key.lower())\n",
    "        save_model(model, directory, 'model')\n",
    "\n",
    "        # Valutazione su validation set\n",
    "        X_val_scaled = scalers[key].transform(X_val)\n",
    "        if pcas[key]:\n",
    "            X_val_scaled = pcas[key].transform(X_val_scaled)\n",
    "        y_pred = model.predict(X_val_scaled)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        print(f\"Validation Performance of {clfName} with {scaler_type} scaler and {'PCA' if use_pca else 'NoPCA'}: MSE={mse}, MAE={mae}, R2={r2}\")\n",
    "\n",
    "        # Cross-validation\n",
    "        mse_cv, mae_cv, r2_cv = cross_val_score_with_preprocessing(\n",
    "            model, X.values, y.values, cv=5, scaler_type=scaler_type, use_pca=use_pca, n_components=52\n",
    "        )\n",
    "        print(f\"Cross-Validation Performance of {clfName} with {scaler_type} scaler and {'PCA' if use_pca else 'NoPCA'}: MSE={mse_cv}, MAE={mae_cv}, R2={r2_cv}\")\n",
    "\n",
    "        # Salvare le performance\n",
    "        performance_dict['Model'].append(clfName)\n",
    "        performance_dict['Scaler'].append(scaler_type)\n",
    "        performance_dict['PCA'].append(use_pca)\n",
    "        performance_dict['MSE_Val'].append(mse)\n",
    "        performance_dict['MAE_Val'].append(mae)\n",
    "        performance_dict['R2_Val'].append(r2)\n",
    "        performance_dict['MSE_CV'].append(mse_cv)\n",
    "        performance_dict['MAE_CV'].append(mae_cv)\n",
    "        performance_dict['R2_CV'].append(r2_cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training KNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "found 0 physical cores < 1\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"c:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 282, in _count_physical_cores\n",
      "    raise ValueError(f\"found {cpu_count_physical} physical cores < 1\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Performance of KNR with Standard scaler and PCA: MSE=95.77045226529194, MAE=7.149356597600872, R2=0.14253933686845544\n",
      "Cross-Validation Performance of KNR with Standard scaler and PCA: MSE=94.88380767324279, MAE=7.103034797263805, R2=0.1388833328796148\n",
      "Validation Performance of KNR with Standard scaler and NoPCA: MSE=89.67204282740155, MAE=6.853474769505305, R2=0.19714016705119275\n",
      "Cross-Validation Performance of KNR with Standard scaler and NoPCA: MSE=88.92059514226231, MAE=6.822715177951821, R2=0.19298139456120558\n",
      "Validation Performance of KNR with MinMax scaler and PCA: MSE=85.17326063249726, MAE=6.556490532368397, R2=0.23741907012498586\n",
      "Cross-Validation Performance of KNR with MinMax scaler and PCA: MSE=84.32230474868643, MAE=6.529097650441163, R2=0.23475225724794607\n",
      "Validation Performance of KNR with MinMax scaler and NoPCA: MSE=84.66267790225041, MAE=6.556375532864084, R2=0.24199046554085202\n",
      "Cross-Validation Performance of KNR with MinMax scaler and NoPCA: MSE=83.89033330028748, MAE=6.532507980569051, R2=0.2386649377271592\n"
     ]
    }
   ],
   "source": [
    "clfName = 'KNR'\n",
    "for scaler_type in preprocessing_options[clfName]['scaler_type']:\n",
    "    for use_pca in preprocessing_options[clfName]['use_pca']:\n",
    "        key = f\"{clfName}_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "        X_train_scaled = scalers[key].transform(X_train)\n",
    "        if pcas[key]:\n",
    "            X_train_scaled = pcas[key].transform(X_train_scaled)\n",
    "\n",
    "        model = train_model(X_train_scaled, y_train, model_type=clfName)\n",
    "        directory = os.path.join('models', key.lower())\n",
    "        save_model(model, directory, 'model')\n",
    "\n",
    "        # Valutazione su validation set\n",
    "        X_val_scaled = scalers[key].transform(X_val)\n",
    "        if pcas[key]:\n",
    "            X_val_scaled = pcas[key].transform(X_val_scaled)\n",
    "        y_pred = model.predict(X_val_scaled)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        print(f\"Validation Performance of {clfName} with {scaler_type} scaler and {'PCA' if use_pca else 'NoPCA'}: MSE={mse}, MAE={mae}, R2={r2}\")\n",
    "\n",
    "        # Cross-validation\n",
    "        mse_cv, mae_cv, r2_cv = cross_val_score_with_preprocessing(\n",
    "            model, X.values, y.values, cv=5, scaler_type=scaler_type, use_pca=use_pca, n_components=52\n",
    "        )\n",
    "        print(f\"Cross-Validation Performance of {clfName} with {scaler_type} scaler and {'PCA' if use_pca else 'NoPCA'}: MSE={mse_cv}, MAE={mae_cv}, R2={r2_cv}\")\n",
    "\n",
    "        # Salvare le performance\n",
    "        performance_dict['Model'].append(clfName)\n",
    "        performance_dict['Scaler'].append(scaler_type)\n",
    "        performance_dict['PCA'].append(use_pca)\n",
    "        performance_dict['MSE_Val'].append(mse)\n",
    "        performance_dict['MAE_Val'].append(mae)\n",
    "        performance_dict['R2_Val'].append(r2)\n",
    "        performance_dict['MSE_CV'].append(mse_cv)\n",
    "        performance_dict['MAE_CV'].append(mae_cv)\n",
    "        performance_dict['R2_CV'].append(r2_cv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfName = 'SVR'\n",
    "for scaler_type in preprocessing_options[clfName]['scaler_type']:\n",
    "    for use_pca in preprocessing_options[clfName]['use_pca']:\n",
    "        key = f\"{clfName}_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "        X_train_scaled = scalers[key].transform(X_train)\n",
    "        if pcas[key]:\n",
    "            X_train_scaled = pcas[key].transform(X_train_scaled)\n",
    "\n",
    "        model = train_model(X_train_scaled, y_train, model_type=clfName)\n",
    "        directory = os.path.join('models', key.lower())\n",
    "        save_model(model, directory, 'model')\n",
    "\n",
    "        # Valutazione su validation set\n",
    "        X_val_scaled = scalers[key].transform(X_val)\n",
    "        if pcas[key]:\n",
    "            X_val_scaled = pcas[key].transform(X_val_scaled)\n",
    "        y_pred = model.predict(X_val_scaled)\n",
    "        mse = mean_squared_error(y_val, y_pred)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "        print(f\"Validation Performance of {clfName} with {scaler_type} scaler and {'PCA' if use_pca else 'NoPCA'}: MSE={mse}, MAE={mae}, R2={r2}\")\n",
    "\n",
    "        # Cross-validation\n",
    "        mse_cv, mae_cv, r2_cv = cross_val_score_with_preprocessing(\n",
    "            model, X.values, y.values, cv=5, scaler_type=scaler_type, use_pca=use_pca, n_components=52\n",
    "        )\n",
    "        print(f\"Cross-Validation Performance of {clfName} with {scaler_type} scaler and {'PCA' if use_pca else 'NoPCA'}: MSE={mse_cv}, MAE={mae_cv}, R2={r2_cv}\")\n",
    "\n",
    "        # Salvare le performance\n",
    "        performance_dict['Model'].append(clfName)\n",
    "        performance_dict['Scaler'].append(scaler_type)\n",
    "        performance_dict['PCA'].append(use_pca)\n",
    "        performance_dict['MSE_Val'].append(mse)\n",
    "        performance_dict['MAE_Val'].append(mae)\n",
    "        performance_dict['R2_Val'].append(r2)\n",
    "        performance_dict['MSE_CV'].append(mse_cv)\n",
    "        performance_dict['MAE_CV'].append(mae_cv)\n",
    "        performance_dict['R2_CV'].append(r2_cv)\n",
    "\n",
    "\n",
    "# Validation Performance of SVR with Standard scaler and PCA: MSE=89.76062511715364, MAE=6.356003295928954, R2=0.19634706409390346\n",
    "# Cross-Validation Performance of SVR with Standard scaler and PCA: MSE=88.47693285428485, MAE=6.314976936016734, R2=0.19714760071223011\n",
    "# Validation Performance of SVR with Standard scaler and NoPCA: MSE=78.95616094014734, MAE=5.841599492634313, R2=0.2930825686139583\n",
    "# Cross-Validation Performance of SVR with Standard scaler and NoPCA: MSE=77.90689735248935, MAE=5.800933341091231, R2=0.29307553783482143\n",
    "# Validation Performance of SVR with MinMax scaler and PCA: MSE=78.74912613182043, MAE=5.808798686392694, R2=0.29493621135908754\n",
    "# Cross-Validation Performance of SVR with MinMax scaler and PCA: MSE=77.6737074521388, MAE=5.765969088166743, R2=0.29518672879002494\n",
    "# Validation Performance of SVR with MinMax scaler and NoPCA: MSE=87.8756541494357, MAE=6.264030260698204, R2=0.21322375641113178\n",
    "# Cross-Validation Performance of SVR with MinMax scaler and NoPCA: MSE=86.66237617661876, MAE=6.2207294324537274, R2=0.21361395079336915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV zip folder's path\n",
    "csv_file_name = '../data.zip'\n",
    "# loading data from csv\n",
    "df = pd.read_csv(csv_file_name)\n",
    "\n",
    "X = df.drop('Year', axis=1)\n",
    "y = df['Year']\n",
    "\n",
    "# Divisione in training e validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dati di training normalizzati MinMaxScaling:\n",
      "[[0.85141255 0.54124099 0.51320672 ... 0.46749133 0.40665778 0.42897257]\n",
      " [0.61060493 0.50150322 0.42992334 ... 0.45522043 0.45247919 0.50174392]\n",
      " [0.44105064 0.43994505 0.52900578 ... 0.48328292 0.3835727  0.38158482]\n",
      " ...\n",
      " [0.81026452 0.47977891 0.52228356 ... 0.45482219 0.40558655 0.40335066]\n",
      " [0.54172766 0.54405139 0.27972061 ... 0.50070901 0.41803509 0.39640128]\n",
      " [0.75397911 0.57359645 0.4808505  ... 0.46099608 0.41463365 0.43697254]]\n"
     ]
    }
   ],
   "source": [
    "X_Validation = X_val.copy()\n",
    "\n",
    "# Min-Max Scaling\n",
    "# Creazione dell'oggetto MinMaxScaler e adattamento solo al training set\n",
    "#file = open(\"scaler.save\",\"wb\") #salvataggio dello scaler sul disco nel file \"scaler.save\"\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "#apply transform on validation set\n",
    "X_val_scaled = scaler.transform(X_Validation)\n",
    "#pickle.dump(scaler, file)\n",
    "#file.close()\n",
    "\n",
    "#name columns after min-max scaling\n",
    "# num_colonne = X_scaled.shape[1]  # Ottieni il numero di colonne\n",
    "# nome_colonne = ['S' + str(i) for i in range(num_colonne)]\n",
    "# X_scaled_df = pd.DataFrame(X_scaled, columns=nome_colonne)\n",
    "\n",
    "# print(\"Dati di training originali:\")\n",
    "# print(X)\n",
    "print(\"\\nDati di training normalizzati MinMaxScaling:\")\n",
    "print(X_scaled)\n",
    "# print(\"\\nDati di validation originali:\")\n",
    "# print(X_Validation)\n",
    "# print(\"\\nDati di validation normalizzati Min-Max:\")\n",
    "# print(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param = {'kernel' : ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "         'C' : [1,5],'degree' : [3,5],'coef0' : [0.01,0.5],'gamma' : ('auto','scale')}\n",
    "\n",
    "modelsvr = SVR()\n",
    "\n",
    "grids = GridSearchCV(modelsvr,param,cv=5,verbose=2, n_jobs=-1) #verbose=2, n_jobs=-1\n",
    "\n",
    "grids.fit(X_scaled,y_train)\n",
    "\n",
    "y_pred=grids.predict(X_val_scaled)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Codice da eseguire Gabri Traning SVR (minMax + PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV zip folder's path\n",
    "csv_file_name = '../data.zip'\n",
    "# loading data from csv\n",
    "df = pd.read_csv(csv_file_name)\n",
    "\n",
    "X = df.drop('Year', axis=1)\n",
    "y = df['Year']\n",
    "\n",
    "# Divisione in training e validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dati di training normalizzati MinMaxScaling:\n",
      "[[0.85141255 0.54124099 0.51320672 ... 0.46749133 0.40665778 0.42897257]\n",
      " [0.61060493 0.50150322 0.42992334 ... 0.45522043 0.45247919 0.50174392]\n",
      " [0.44105064 0.43994505 0.52900578 ... 0.48328292 0.3835727  0.38158482]\n",
      " ...\n",
      " [0.81026452 0.47977891 0.52228356 ... 0.45482219 0.40558655 0.40335066]\n",
      " [0.54172766 0.54405139 0.27972061 ... 0.50070901 0.41803509 0.39640128]\n",
      " [0.75397911 0.57359645 0.4808505  ... 0.46099608 0.41463365 0.43697254]]\n"
     ]
    }
   ],
   "source": [
    "X_Validation = X_val.copy()\n",
    "\n",
    "# Min-Max Scaling\n",
    "# Creazione dell'oggetto MinMaxScaler e adattamento solo al training set\n",
    "#file = open(\"scaler.save\",\"wb\") #salvataggio dello scaler sul disco nel file \"scaler.save\"\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "#apply transform on validation set\n",
    "X_val_scaled = scaler.transform(X_Validation)\n",
    "#pickle.dump(scaler, file)\n",
    "#file.close()\n",
    "\n",
    "#name columns after min-max scaling\n",
    "# num_colonne = X_scaled.shape[1]  # Ottieni il numero di colonne\n",
    "# nome_colonne = ['S' + str(i) for i in range(num_colonne)]\n",
    "# X_scaled_df = pd.DataFrame(X_scaled, columns=nome_colonne)\n",
    "\n",
    "# print(\"Dati di training originali:\")\n",
    "# print(X)\n",
    "print(\"\\nDati di training normalizzati MinMaxScaling:\")\n",
    "print(X_scaled)\n",
    "# print(\"\\nDati di validation originali:\")\n",
    "# print(X_Validation)\n",
    "# print(\"\\nDati di validation normalizzati Min-Max:\")\n",
    "# print(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizializzare l'oggetto PCA\n",
    "pca = PCA(n_components=52)\n",
    "X_decomposed = pca.fit_transform(X_scaled)\n",
    "#pca.get_feature_names_out(X_scaled_df.columns)\n",
    "\n",
    "# Ottieni i vettori delle componenti principali\n",
    "components = pca.components_\n",
    "\n",
    "#validation data after PCA\n",
    "X_val_decomposed = pca.transform(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param = {'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "         'C' : [1,5,10],\n",
    "         'degree' : [3,8],\n",
    "         'coef0' : [0.01,10,0.5],\n",
    "         'gamma' : ['auto','scale']}\n",
    "\n",
    "modelsvr = SVR(cache_size=200)\n",
    "\n",
    "grids = GridSearchCV(modelsvr,param,cv=5,verbose=2, n_jobs=-1) #verbose=2, n_jobs=-1\n",
    "\n",
    "grids.fit(X_decomposed,y_train)\n",
    "\n",
    "y_pred=grids.predict(X_val_decomposed)\n",
    "\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Initial MSE before training: 3992763.25\n",
      "Initial MAE before training: 1998.16259765625\n",
      "Initial R2 before training: -36563.94140625\n",
      "Early stopping\n",
      "Final MSE after training: 75.72067260742188\n",
      "Final MAE after training: 6.161563396453857\n",
      "Final R2 after training: 0.30656498670578003\n",
      "Final evaluation on the test set\n",
      "Final MSE on the test set: 77.37577819824219\n",
      "Final MAE on the test set: 6.265819549560547\n",
      "Final R2 on the test set: 0.3131319284439087\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Funzione per fissare la casualit√†\n",
    "def fix_random(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Definizione del Dataset personalizzato\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y.values).view(-1, 1)\n",
    "        self.num_features = X.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx,:], self.y[idx]\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, hidden_size4):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.fc2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.fc3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.fc4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "        self.fc5 = nn.Linear(hidden_size4, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.relu(self.fc1(x))\n",
    "        h = self.relu(self.fc2(h))\n",
    "        h = self.relu(self.fc3(h))\n",
    "        h = self.relu(self.fc4(h))\n",
    "        output = self.fc5(h)\n",
    "        return output\n",
    "\n",
    "# Funzione per valutare le performance sul validation e test set\n",
    "def test_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    y_test = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, targets in data_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            output = model(data)\n",
    "            y_pred.append(output.cpu().numpy())\n",
    "            y_test.append(targets.cpu().numpy())\n",
    "\n",
    "    y_test = np.concatenate(y_test).squeeze()\n",
    "    y_pred = np.concatenate(y_pred).squeeze()\n",
    "\n",
    "    return y_test, y_pred\n",
    "\n",
    "# Funzione per il processo di addestramento\n",
    "def train_model(model, criterion, optimizer, num_epochs, train_loader, val_loader, device, writer, log_name=\"model\", patience=10):\n",
    "    n_iter = 0\n",
    "    best_valid_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    early_stop = False\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for data, targets in train_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(data)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(y_pred, targets)\n",
    "            writer.add_scalar(\"Loss/train\", loss.item(), n_iter)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            n_iter += 1\n",
    "\n",
    "        # Validation\n",
    "        labels, y_pred = test_model(model, val_loader, device)\n",
    "        loss_val = criterion(torch.tensor(y_pred), torch.tensor(labels))\n",
    "        writer.add_scalar(\"Loss/val\", loss_val.item(), epoch)\n",
    "\n",
    "        # Save best model\n",
    "        if loss_val.item() < best_valid_loss:\n",
    "            best_valid_loss = loss_val.item()\n",
    "            epochs_no_improve = 0\n",
    "            if not os.path.exists('models'):\n",
    "                os.makedirs('models')\n",
    "            torch.save(model.state_dict(), 'models/'+log_name)\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                early_stop = True\n",
    "\n",
    "    return model\n",
    "\n",
    "# Look for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "seed = 89\n",
    "fix_random(seed)\n",
    "\n",
    "# Train hyperparameters\n",
    "num_epochs = 150\n",
    "initial_learning_rate = 0.0001\n",
    "batch_size = 64  # Dimensione del batch fissa\n",
    "hidden_size1 = 128\n",
    "hidden_size2 = 64\n",
    "hidden_size3 = 32\n",
    "hidden_size4 = 16\n",
    "\n",
    "# CSV zip folder's path\n",
    "csv_file_name = '../data.zip'\n",
    "# loading data from csv\n",
    "data = pd.read_csv(csv_file_name)\n",
    "\n",
    "# Caricamento del dataset\n",
    "X = data.drop('Year', axis=1)\n",
    "y = data['Year']\n",
    "\n",
    "# Suddivisione dei dati in train, val, test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=seed)  # 0.9 x 0.25\n",
    "\n",
    "# Scaling dei dati\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=52)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_val_pca = pca.transform(X_val_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Creazione del test loader\n",
    "test_dataset = MyDataset(X_test_pca, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "# Creazione del validation set fisso\n",
    "val_dataset = MyDataset(X_val_pca, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "\n",
    "# Creazione del train loader\n",
    "train_dataset = MyDataset(X_train_pca, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Definisci il modello\n",
    "model = FeedForward(train_dataset.num_features, hidden_size1, hidden_size2, hidden_size3, hidden_size4)\n",
    "model.to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=initial_learning_rate)\n",
    "\n",
    "# Start tensorboard\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# Test before the training\n",
    "y_val_initial, y_pred_initial = test_model(model, val_loader, device)\n",
    "initial_mse = torch.mean((torch.tensor(y_val_initial) - torch.tensor(y_pred_initial)) ** 2).item()\n",
    "initial_mae = mean_absolute_error(y_val_initial, y_pred_initial)\n",
    "initial_r2 = r2_score(y_val_initial, y_pred_initial)\n",
    "print(f\"Initial MSE before training: {initial_mse}\")\n",
    "print(f\"Initial MAE before training: {initial_mae}\")\n",
    "print(f\"Initial R2 before training: {initial_r2}\")\n",
    "\n",
    "# Train the model\n",
    "model = train_model(model, criterion, optimizer, num_epochs, train_loader, val_loader, device, writer)\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(\"models/model\"))\n",
    "model.to(device)\n",
    "\n",
    "# Test after the training\n",
    "y_val_final, y_pred_final = test_model(model, val_loader, device)\n",
    "final_mse = torch.mean((torch.tensor(y_val_final) - torch.tensor(y_pred_final)) ** 2).item()\n",
    "final_mae = mean_absolute_error(y_val_final, y_pred_final)\n",
    "final_r2 = r2_score(y_val_final, y_pred_final)\n",
    "print(f\"Final MSE after training: {final_mse}\")\n",
    "print(f\"Final MAE after training: {final_mae}\")\n",
    "print(f\"Final R2 after training: {final_r2}\")\n",
    "\n",
    "# Test finale sul test set\n",
    "print(\"Final evaluation on the test set\")\n",
    "y_test_final, y_pred_final = test_model(model, test_loader, device)\n",
    "test_mse = torch.mean((torch.tensor(y_test_final) - torch.tensor(y_pred_final)) ** 2).item()\n",
    "test_mae = mean_absolute_error(y_test_final, y_pred_final)\n",
    "test_r2 = r2_score(y_test_final, y_pred_final)\n",
    "print(f\"Final MSE on the test set: {test_mse}\")\n",
    "print(f\"Final MAE on the test set: {test_mae}\")\n",
    "print(f\"Final R2 on the test set: {test_r2}\")\n",
    "\n",
    "# Close tensorboard writer after training\n",
    "writer.flush()\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEED FORWARD FINALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Early stopping\n",
      "Trained with parameters: {'num_epochs': 150, 'negative_slope': 0.01, 'learning_rate': 0.001, 'hidden_size8': 4, 'hidden_size7': 32, 'hidden_size6': 16, 'hidden_size5': 64, 'hidden_size4': 64, 'hidden_size3': 64, 'hidden_size2': 512, 'hidden_size1': 256, 'batch_size': 128}, MSE: 231.80857849121094, MAE: 12.55402946472168, R2: -1.0754497051239014\n",
      "Trained with parameters: {'num_epochs': 200, 'negative_slope': 0.001, 'learning_rate': 0.001, 'hidden_size8': 4, 'hidden_size7': 16, 'hidden_size6': 16, 'hidden_size5': 32, 'hidden_size4': 128, 'hidden_size3': 256, 'hidden_size2': 256, 'hidden_size1': 512, 'batch_size': 128}, MSE: 2832427.25, MAE: 1682.94873046875, R2: -25358.541015625\n",
      "Trained with parameters: {'num_epochs': 150, 'negative_slope': 0.09, 'learning_rate': 1e-05, 'hidden_size8': 8, 'hidden_size7': 32, 'hidden_size6': 32, 'hidden_size5': 64, 'hidden_size4': 128, 'hidden_size3': 64, 'hidden_size2': 512, 'hidden_size1': 1024, 'batch_size': 256}, MSE: 77.63011169433594, MAE: 6.323260307312012, R2: 0.3049549460411072\n",
      "Early stopping\n",
      "Trained with parameters: {'num_epochs': 250, 'negative_slope': 0.01, 'learning_rate': 1e-05, 'hidden_size8': 8, 'hidden_size7': 32, 'hidden_size6': 32, 'hidden_size5': 32, 'hidden_size4': 64, 'hidden_size3': 64, 'hidden_size2': 128, 'hidden_size1': 1024, 'batch_size': 64}, MSE: 77.0397720336914, MAE: 6.513062000274658, R2: 0.3102405071258545\n",
      "Early stopping\n",
      "Trained with parameters: {'num_epochs': 250, 'negative_slope': 0.01, 'learning_rate': 0.0001, 'hidden_size8': 8, 'hidden_size7': 16, 'hidden_size6': 32, 'hidden_size5': 32, 'hidden_size4': 128, 'hidden_size3': 256, 'hidden_size2': 128, 'hidden_size1': 256, 'batch_size': 64}, MSE: 79.01583099365234, MAE: 6.08290433883667, R2: 0.2925482988357544\n",
      "Trained with parameters: {'num_epochs': 150, 'negative_slope': 0.09, 'learning_rate': 1e-05, 'hidden_size8': 4, 'hidden_size7': 32, 'hidden_size6': 32, 'hidden_size5': 64, 'hidden_size4': 64, 'hidden_size3': 64, 'hidden_size2': 256, 'hidden_size1': 256, 'batch_size': 256}, MSE: 82.06446075439453, MAE: 6.432555675506592, R2: 0.26525312662124634\n",
      "Early stopping\n",
      "Trained with parameters: {'num_epochs': 200, 'negative_slope': 0.001, 'learning_rate': 0.001, 'hidden_size8': 8, 'hidden_size7': 16, 'hidden_size6': 16, 'hidden_size5': 64, 'hidden_size4': 128, 'hidden_size3': 256, 'hidden_size2': 128, 'hidden_size1': 1024, 'batch_size': 128}, MSE: 142.47409057617188, MAE: 9.175116539001465, R2: -0.27561187744140625\n",
      "Trained with parameters: {'num_epochs': 200, 'negative_slope': 0.01, 'learning_rate': 0.0001, 'hidden_size8': 4, 'hidden_size7': 16, 'hidden_size6': 32, 'hidden_size5': 32, 'hidden_size4': 128, 'hidden_size3': 256, 'hidden_size2': 128, 'hidden_size1': 512, 'batch_size': 128}, MSE: 3868308.75, MAE: 1966.7735595703125, R2: -34633.08984375\n",
      "Trained with parameters: {'num_epochs': 200, 'negative_slope': 0.001, 'learning_rate': 1e-06, 'hidden_size8': 4, 'hidden_size7': 32, 'hidden_size6': 16, 'hidden_size5': 32, 'hidden_size4': 128, 'hidden_size3': 128, 'hidden_size2': 128, 'hidden_size1': 256, 'batch_size': 128}, MSE: 103.64258575439453, MAE: 7.02398157119751, R2: 0.07205778360366821\n",
      "Early stopping\n",
      "Trained with parameters: {'num_epochs': 250, 'negative_slope': 0.001, 'learning_rate': 0.0001, 'hidden_size8': 8, 'hidden_size7': 8, 'hidden_size6': 16, 'hidden_size5': 32, 'hidden_size4': 64, 'hidden_size3': 64, 'hidden_size2': 128, 'hidden_size1': 1024, 'batch_size': 256}, MSE: 76.27033996582031, MAE: 6.373352527618408, R2: 0.3171294927597046\n",
      "Best parameters: {'num_epochs': 250, 'negative_slope': 0.001, 'learning_rate': 0.0001, 'hidden_size8': 8, 'hidden_size7': 8, 'hidden_size6': 16, 'hidden_size5': 32, 'hidden_size4': 64, 'hidden_size3': 64, 'hidden_size2': 128, 'hidden_size1': 1024, 'batch_size': 256}, MSE: 76.27033996582031, MAE: 6.373352527618408, R2: 0.3171294927597046\n",
      "Final MSE on the validation set: 75.81117248535156\n",
      "Final MAE on the validation set: 6.167088985443115\n",
      "Final R2 on the validation set: 0.3212406039237976\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.decomposition import PCA\n",
    "from feedforward import FeedForward\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "import hashlib\n",
    "\n",
    "# Function to set random seed\n",
    "def fix_random(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Training process function\n",
    "def train_model(model, criterion, optimizer, num_epochs, train_loader, val_loader, device, writer, log_name=\"FF\", patience=10):\n",
    "    n_iter = 0\n",
    "    best_valid_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    early_stop = False\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        if early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        for data, targets in train_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            y_pred = model(data)\n",
    "\n",
    "            # Compute Loss\n",
    "            loss = criterion(y_pred, targets)\n",
    "            writer.add_scalar(\"Loss/train\", loss.item(), n_iter)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            n_iter += 1\n",
    "\n",
    "        # Validation\n",
    "        labels, y_pred = test_model(model, val_loader, device)\n",
    "        loss_val = criterion(torch.tensor(y_pred), torch.tensor(labels))\n",
    "        writer.add_scalar(\"Loss/val\", loss_val.item(), epoch)\n",
    "\n",
    "        # Save best model\n",
    "        if loss_val.item() < best_valid_loss:\n",
    "            best_valid_loss = loss_val.item()\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'params': params\n",
    "            }, '../pickle_saves/models/FF.save')\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                early_stop = True\n",
    "\n",
    "    return model\n",
    "\n",
    "# Function to generate a unique log directory name based on parameters\n",
    "def get_log_dir(params):\n",
    "    param_str = str(sorted(params.items()))\n",
    "    param_hash = hashlib.md5(param_str.encode('utf-8')).hexdigest()\n",
    "    return f\"runs/param_{param_hash}\"\n",
    "\n",
    "# Look for GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "seed = 89\n",
    "fix_random(seed)\n",
    "\n",
    "# CSV zip folder's path\n",
    "csv_file_name = '../data.zip'\n",
    "# loading data from csv\n",
    "data = pd.read_csv(csv_file_name)\n",
    "\n",
    "# Loading the dataset\n",
    "X = data.drop('Year', axis=1)\n",
    "y = data['Year']\n",
    "\n",
    "# Splitting the data into train, val --> 80% training - 20% validation - NO TEST SET\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Scaling the data\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=52)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_val_pca = pca.transform(X_val_scaled)\n",
    "\n",
    "# Creating the validation set\n",
    "val_dataset = MyDataset(X_val_pca, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "\n",
    "# Creating the train loader\n",
    "train_dataset = MyDataset(X_train_pca, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define the hyperparameter space\n",
    "param_grid = {\n",
    "    'num_epochs': [150, 200, 250],\n",
    "    'learning_rate': [0.000001, 0.00001, 0.0001, 0.001],\n",
    "    'batch_size': [64, 128, 256],\n",
    "    'hidden_size1': [256, 512, 1024],\n",
    "    'hidden_size2': [128, 256, 512],\n",
    "    'hidden_size3': [64, 128, 256],\n",
    "    'hidden_size4': [64, 128],\n",
    "    'hidden_size5': [32, 64],\n",
    "    'hidden_size6': [16, 32],\n",
    "    'hidden_size7': [8, 16, 32],\n",
    "    'hidden_size8': [4, 8],\n",
    "    'negative_slope': [0.001, 0.01, 0.09] #0.01 default e solitamente migliore\n",
    "}\n",
    "\n",
    "# Number of parameter samples to evaluate\n",
    "n_iter_search = 10\n",
    "\n",
    "# Generate parameter samples\n",
    "param_list = list(ParameterSampler(param_grid, n_iter=n_iter_search, random_state=seed))\n",
    "\n",
    "# Function to run the training with given hyperparameters\n",
    "def random_search(params):\n",
    "    model = FeedForward(\n",
    "        train_dataset.num_features, \n",
    "        params['hidden_size1'], \n",
    "        params['hidden_size2'], \n",
    "        params['hidden_size3'], \n",
    "        params['hidden_size4'], \n",
    "        params['hidden_size5'], \n",
    "        params['hidden_size6'], \n",
    "        params['hidden_size7'], \n",
    "        params['hidden_size8'], \n",
    "        params['negative_slope']\n",
    "    )\n",
    "    model.to(device)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "    \n",
    "    # Create DataLoaders with the new batch size\n",
    "    train_loader = DataLoader(train_dataset, batch_size=params['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "    \n",
    "    log_dir = get_log_dir(params)\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "    model = train_model(model, criterion, optimizer, params['num_epochs'], train_loader, val_loader, device, writer, log_name=log_dir)\n",
    "    \n",
    "    y_val_final, y_pred_final = test_model(model, val_loader, device)\n",
    "    final_mse = torch.mean((torch.tensor(y_val_final) - torch.tensor(y_pred_final)) ** 2).item()\n",
    "    final_mae = mean_absolute_error(y_val_final, y_pred_final)\n",
    "    final_r2 = r2_score(y_val_final, y_pred_final)\n",
    "    \n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "    \n",
    "    return {\n",
    "        'params': params,\n",
    "        'mse': final_mse,\n",
    "        'mae': final_mae,\n",
    "        'r2': final_r2,\n",
    "        'model': model\n",
    "    }\n",
    "\n",
    "# Run the training for all parameter samples\n",
    "results = []\n",
    "for params in param_list:\n",
    "    result = random_search(params)\n",
    "    results.append(result)\n",
    "    print(f\"Trained with parameters: {params}, MSE: {result['mse']}, MAE: {result['mae']}, R2: {result['r2']}\")\n",
    "\n",
    "# Find the best parameters\n",
    "best_result = min(results, key=lambda x: x['mse'])\n",
    "print(f\"Best parameters: {best_result['params']}, MSE: {best_result['mse']}, MAE: {best_result['mae']}, R2: {best_result['r2']}\")\n",
    "\n",
    "# Load the best model and parameters\n",
    "checkpoint = torch.load('../pickle_saves/models/FF.save')\n",
    "best_params = checkpoint['params']\n",
    "\n",
    "# Create a new model instance with the best parameters\n",
    "loaded_model = FeedForward(\n",
    "    train_dataset.num_features, \n",
    "    best_params['hidden_size1'], \n",
    "    best_params['hidden_size2'], \n",
    "    best_params['hidden_size3'], \n",
    "    best_params['hidden_size4'], \n",
    "    best_params['hidden_size5'], \n",
    "    best_params['hidden_size6'], \n",
    "    best_params['hidden_size7'], \n",
    "    best_params['hidden_size8'], \n",
    "    best_params['negative_slope']\n",
    ")\n",
    "\n",
    "# Load the state dictionary\n",
    "loaded_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "loaded_model.to(device)\n",
    "\n",
    "# Test the loaded model on the validation set\n",
    "loaded_model.eval()\n",
    "y_val_final, y_pred_final = test_model(loaded_model, val_loader, device)\n",
    "final_mse = torch.mean((torch.tensor(y_val_final) - torch.tensor(y_pred_final)) ** 2).item()\n",
    "final_mae = mean_absolute_error(y_val_final, y_pred_final)\n",
    "final_r2 = r2_score(y_val_final, y_pred_final)\n",
    "print(f\"Final MSE on the validation set: {final_mse}\")\n",
    "print(f\"Final MAE on the validation set: {final_mae}\")\n",
    "print(f\"Final R2 on the validation set: {final_r2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAB TRANSFORMER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:53:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">939</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">140</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m10:53:00\u001b[0m,\u001b[1;36m939\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m140\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:53:00</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">952</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">524</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m10:53:00\u001b[0m,\u001b[1;36m952\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m524\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:53:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">000</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:499</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m10:53:01\u001b[0m,\u001b[1;36m000\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:499\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:53:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">574</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabTransformerModel    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m10:53:01\u001b[0m,\u001b[1;36m100\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m574\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabTransformerModel    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:53:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">136</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m10:53:01\u001b[0m,\u001b[1;36m136\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m340\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:53:01</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">306</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">652</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m10:53:01\u001b[0m,\u001b[1;36m306\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m652\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:639: Checkpoint directory C:\\Users\\Gabriele\\Documents\\GitHub\\song-publication-year-recognizer\\TrainingModule\\saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                   </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>‚îÇ _backbone        ‚îÇ TabTransformerBackbone ‚îÇ  308 K ‚îÇ\n",
       "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>‚îÇ _embedding_layer ‚îÇ Embedding2dLayer       ‚îÇ      0 ‚îÇ\n",
       "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>‚îÇ _head            ‚îÇ LinearHead             ‚îÇ     91 ‚îÇ\n",
       "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>‚îÇ loss             ‚îÇ MSELoss                ‚îÇ      0 ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mType                  \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m‚îÇ _backbone        ‚îÇ TabTransformerBackbone ‚îÇ  308 K ‚îÇ\n",
       "‚îÇ\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m‚îÇ _embedding_layer ‚îÇ Embedding2dLayer       ‚îÇ      0 ‚îÇ\n",
       "‚îÇ\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m‚îÇ _head            ‚îÇ LinearHead             ‚îÇ     91 ‚îÇ\n",
       "‚îÇ\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m‚îÇ loss             ‚îÇ MSELoss                ‚îÇ      0 ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 308 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 308 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 1                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 308 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 308 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 1                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44cbc4a812d408692c90765364afdfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\da\n",
       "ta_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing\n",
       "the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\da\n",
       "ta_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing\n",
       "the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\da\n",
       "ta_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\da\n",
       "ta_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:03:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">068</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">663</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m14:03:19\u001b[0m,\u001b[1;36m068\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m663\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">14:03:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">071</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1489</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m14:03:19\u001b[0m,\u001b[1;36m071\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1489\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d11c4083260452fa571cc91dd6cea1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\">        Test metric        </span>‚îÉ<span style=\"font-weight: bold\">       DataLoader 0        </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">     85.21570587158203     </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">  test_mean_squared_error  </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">     85.21570587158203     </span>‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m    85.21570587158203    \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m test_mean_squared_error \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m    85.21570587158203    \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_loss': 85.21570587158203, 'test_mean_squared_error': 85.21570587158203}]\n",
      "       Year_prediction\n",
      "0          1992.533325\n",
      "1          1991.585571\n",
      "2          1989.807495\n",
      "3          1997.795654\n",
      "4          1990.723633\n",
      "...                ...\n",
      "25213      2001.279663\n",
      "25214      1983.474731\n",
      "25215      1996.569336\n",
      "25216      1998.419800\n",
      "25217      2000.441284\n",
      "\n",
      "[25218 rows x 1 columns]\n",
      "MSE:  87.64905173338944  MAE: 6.8474529882626625  MAPE: 0.34367431697567447  R2_SCORE: 0.22193562984466553\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.config import DataConfig, TrainerConfig, OptimizerConfig\n",
    "from pytorch_tabular.models import TabTransformerConfig\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"../data.zip\")\n",
    "X = data[data.columns[1:]]\n",
    "Y = data[data.columns[0]]\n",
    "\n",
    "# `num_col_names` lista con i nomi delle 89 colonne numeriche\n",
    "num_col_names = X.columns.tolist()\n",
    "\n",
    "# Split data\n",
    "seed = 89\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=seed, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=seed, shuffle=True)  # 0.9 x 0.25 = 0.22 di validation\n",
    "\n",
    "# Scaling dei dati MinMaxScaler()\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# MinMaxScaling e creazione DataFrame per train, validation, test\n",
    "train = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "train['Year'] = y_train.values\n",
    "\n",
    "val = pd.DataFrame(X_val_scaled, columns=X.columns)\n",
    "val['Year'] = y_val.values\n",
    "\n",
    "test = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "test['Year'] = y_test.values\n",
    "\n",
    "# Configurations\n",
    "data_config = DataConfig(\n",
    "    target=[\"Year\"],  # target should always be a list\n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=[],\n",
    "    normalize_continuous_features=False\n",
    "    # num_workers=21 # Windows does not support num_workers > 0. Setting num_workers to 0\n",
    ")\n",
    "\n",
    "# Configurazione del trainer\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=False,\n",
    "    batch_size=32, \n",
    "    max_epochs=150,\n",
    "    early_stopping_patience=10,  # Numero di epoche di attesa per il miglioramento\n",
    "    precision=32,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# Configurazione dell'ottimizzatore\n",
    "optimizer_config = OptimizerConfig(\n",
    "    optimizer=\"AdamW\"\n",
    ")\n",
    "\n",
    "# Configurazione del modello TabTransformer\n",
    "model_config = TabTransformerConfig(\n",
    "    task=\"regression\",\n",
    "    learning_rate=0.00001,\n",
    "    num_heads=8,\n",
    "    num_attn_blocks=6,\n",
    "    ff_hidden_multiplier=6,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# Initialize and train model\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "tabular_model.fit(train=train, validation=val, seed=seed)\n",
    "\n",
    "# Valutare il modello\n",
    "result = tabular_model.evaluate(val)\n",
    "print(result)\n",
    "\n",
    "# Fare predizioni\n",
    "pred_df = tabular_model.predict(test)\n",
    "print(pred_df)\n",
    "\n",
    "y_true = test['Year']\n",
    "y_pred = pred_df['Year_prediction']\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "r2score = r2_score(y_true, y_pred)\n",
    "print(\"MSE: \", mse, \" MAE:\", mae, \" MAPE:\", mape, \" R2_SCORE:\", r2score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tab transformer 2 con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:33:47</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">715</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">140</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m19:33:47\u001b[0m,\u001b[1;36m715\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m140\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:33:47</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">736</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">524</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m19:33:47\u001b[0m,\u001b[1;36m736\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m524\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:33:47</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">818</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:499</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m19:33:47\u001b[0m,\u001b[1;36m818\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:499\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:33:47</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">885</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">574</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabTransformerModel    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m19:33:47\u001b[0m,\u001b[1;36m885\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m574\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabTransformerModel    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:33:47</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">941</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m19:33:47\u001b[0m,\u001b[1;36m941\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m340\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:33:47</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">956</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">652</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m19:33:47\u001b[0m,\u001b[1;36m956\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m652\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\callbacks\\model_checkpoint.py:639: Checkpoint directory C:\\Users\\Gabriele\\Documents\\GitHub\\song-publication-year-recognizer\\TrainingModule\\saved_models exists and is not empty.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                   </span>‚îÉ<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>‚îÇ _backbone        ‚îÇ TabTransformerBackbone ‚îÇ  4.9 M ‚îÇ\n",
       "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>‚îÇ _embedding_layer ‚îÇ Embedding2dLayer       ‚îÇ      0 ‚îÇ\n",
       "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>‚îÇ _head            ‚îÇ LinearHead             ‚îÇ     53 ‚îÇ\n",
       "‚îÇ<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>‚îÇ loss             ‚îÇ MSELoss                ‚îÇ      0 ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mType                  \u001b[0m\u001b[1;35m \u001b[0m‚îÉ\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m‚îÇ _backbone        ‚îÇ TabTransformerBackbone ‚îÇ  4.9 M ‚îÇ\n",
       "‚îÇ\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m‚îÇ _embedding_layer ‚îÇ Embedding2dLayer       ‚îÇ      0 ‚îÇ\n",
       "‚îÇ\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m‚îÇ _head            ‚îÇ LinearHead             ‚îÇ     53 ‚îÇ\n",
       "‚îÇ\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m‚îÇ loss             ‚îÇ MSELoss                ‚îÇ      0 ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.9 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.9 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 19                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.9 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.9 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 19                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2390b507e94a85ad73f4c432d7d6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\da\n",
       "ta_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing\n",
       "the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\da\n",
       "ta_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing\n",
       "the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">c:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\da\n",
       "ta_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "c:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\da\n",
       "ta_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider \n",
       "increasing the value of the `num_workers` argument` to `num_workers=21` in the `DataLoader` to improve performance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=150` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:21:11</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">365</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">663</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m21:21:11\u001b[0m,\u001b[1;36m365\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m663\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">21:21:11</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">367</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1489</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m11\u001b[0m \u001b[1;92m21:21:11\u001b[0m,\u001b[1;36m367\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1489\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863303b695f5408ebd7792247cb9bd0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\">             Test metric             </span>‚îÉ<span style=\"font-weight: bold\">            DataLoader 0             </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">              test_loss              </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">             1324310.625             </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">      test_mean_absolute_error       </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">          1150.748779296875          </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\"> test_mean_absolute_percentage_error </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">         0.5758378505706787          </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">       test_mean_squared_error       </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">             1324310.625             </span>‚îÇ\n",
       "‚îÇ<span style=\"color: #008080; text-decoration-color: #008080\">            test_r2_score            </span>‚îÇ<span style=\"color: #800080; text-decoration-color: #800080\">          -13198.2822265625          </span>‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1m            Test metric            \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m           DataLoader 0            \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m             test_loss             \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m            1324310.625            \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m     test_mean_absolute_error      \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m         1150.748779296875         \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36mtest_mean_absolute_percentage_error\u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m        0.5758378505706787         \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m      test_mean_squared_error      \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m            1324310.625            \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îÇ\u001b[36m \u001b[0m\u001b[36m           test_r2_score           \u001b[0m\u001b[36m \u001b[0m‚îÇ\u001b[35m \u001b[0m\u001b[35m         -13198.2822265625         \u001b[0m\u001b[35m \u001b[0m‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'test_loss': 1324310.625, 'test_mean_squared_error': 1324310.625, 'test_mean_absolute_error': 1150.748779296875, 'test_mean_absolute_percentage_error': 0.5758378505706787, 'test_r2_score': -13198.2822265625}]\n",
      "       Year_prediction\n",
      "0           841.612244\n",
      "1           839.556030\n",
      "2           838.818909\n",
      "3           847.098694\n",
      "4           839.342712\n",
      "...                ...\n",
      "25213       851.963867\n",
      "25214       835.353455\n",
      "25215       845.740662\n",
      "25216       849.822876\n",
      "25217       854.007019\n",
      "\n",
      "[25218 rows x 1 columns]\n",
      "MSE:  1324188.9807020717  MAE: 1150.6959721482579  MAPE: 57.5831031900501  R2_SCORE: -11753.8828125\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.config import DataConfig, TrainerConfig, OptimizerConfig\n",
    "from pytorch_tabular.models import TabTransformerConfig\n",
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"../data.zip\")\n",
    "X = data[data.columns[1:]]\n",
    "Y = data[data.columns[0]]\n",
    "\n",
    "# Split data\n",
    "seed = 89\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=seed, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=seed, shuffle=True)  # 0.9 x 0.25 = 0.22 di validation\n",
    "\n",
    "# Scaling dei dati MinMaxScaler()\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=52)\n",
    "X_train_pca = pca.fit_transform(X_scaled)\n",
    "X_val_pca = pca.transform(X_val_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Create new column names for PCA components\n",
    "pca_col_names = [f'PCA_{i}' for i in range(1, 53)]\n",
    "\n",
    "# MinMaxScaling e creazione DataFrame per train, validation, test\n",
    "train = pd.DataFrame(X_train_pca, columns=pca_col_names)\n",
    "train['Year'] = y_train.values\n",
    "\n",
    "val = pd.DataFrame(X_val_pca, columns=pca_col_names)\n",
    "val['Year'] = y_val.values\n",
    "\n",
    "test = pd.DataFrame(X_test_pca, columns=pca_col_names)\n",
    "test['Year'] = y_test.values\n",
    "\n",
    "# Configurations\n",
    "data_config = DataConfig(\n",
    "    target=[\"Year\"],  # target should always be a list\n",
    "    continuous_cols=pca_col_names,\n",
    "    categorical_cols=[],\n",
    "    normalize_continuous_features=False\n",
    ")\n",
    "\n",
    "# Configurazione del trainer\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=False,\n",
    "    batch_size=32, \n",
    "    max_epochs=150,\n",
    "    early_stopping_patience=10,  # Numero di epoche di attesa per il miglioramento\n",
    "    precision=32,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "# Configurazione dell'ottimizzatore\n",
    "optimizer_config = OptimizerConfig(\n",
    "    optimizer=\"AdamW\"\n",
    ")\n",
    "\n",
    "# Configurazione del modello TabTransformer\n",
    "model_config = TabTransformerConfig(\n",
    "    task=\"regression\",\n",
    "    learning_rate=0.00001,\n",
    "    num_heads=32,\n",
    "    num_attn_blocks=24,\n",
    "    ff_hidden_multiplier=24,\n",
    "    seed=seed,\n",
    "    metrics=[\"mean_squared_error\",\"mean_absolute_error\",\"mean_absolute_percentage_error\",\"r2_score\"],  \n",
    "    )\n",
    "\n",
    "# Initialize and train model\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "tabular_model.fit(train=train, validation=val, seed=seed)\n",
    "\n",
    "# Valutare il modello\n",
    "result = tabular_model.evaluate(val)\n",
    "print(result)\n",
    "\n",
    "# Fare predizioni\n",
    "pred_df = tabular_model.predict(test)\n",
    "print(pred_df)\n",
    "\n",
    "y_true = test['Year']\n",
    "y_pred = pred_df['Year_prediction']\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "r2score = r2_score(y_true, y_pred)\n",
    "print(\"MSE: \", mse, \" MAE:\", mae, \" MAPE:\", mape, \" R2_SCORE:\", r2score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAB TRANSFORMER CON PIU' PARAMETRI ANCORA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:18:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">598</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">140</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m19:18:36\u001b[0m,\u001b[1;36m598\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m140\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:18:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">614</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">524</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m19:18:36\u001b[0m,\u001b[1;36m614\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m524\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:18:36</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">650</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:499</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m19:18:36\u001b[0m,\u001b[1;36m650\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:499\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:18:37</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">017</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">574</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: TabTransformerModel    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m19:18:37\u001b[0m,\u001b[1;36m017\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m574\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: TabTransformerModel    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">19:18:37</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">048</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.models.base_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">204</span><span style=\"font-weight: bold\">}</span> - ERROR - mean_absolute_error is not a valid loss\n",
       "defined in the torch.nn module                                                                                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m19:18:37\u001b[0m,\u001b[1;36m048\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.models.base_model:\u001b[1;36m204\u001b[0m\u001b[1m}\u001b[0m - ERROR - mean_absolute_error is not a valid loss\n",
       "defined in the torch.nn module                                                                                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'mean_absolute_error'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 80\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# Initialize and train model\u001b[39;00m\n\u001b[0;32m     73\u001b[0m tabular_model \u001b[38;5;241m=\u001b[39m TabularModel(\n\u001b[0;32m     74\u001b[0m     data_config\u001b[38;5;241m=\u001b[39mdata_config,\n\u001b[0;32m     75\u001b[0m     model_config\u001b[38;5;241m=\u001b[39mmodel_config,\n\u001b[0;32m     76\u001b[0m     optimizer_config\u001b[38;5;241m=\u001b[39moptimizer_config,\n\u001b[0;32m     77\u001b[0m     trainer_config\u001b[38;5;241m=\u001b[39mtrainer_config,\n\u001b[0;32m     78\u001b[0m )\n\u001b[1;32m---> 80\u001b[0m \u001b[43mtabular_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[0;32m     83\u001b[0m result \u001b[38;5;241m=\u001b[39m tabular_model\u001b[38;5;241m.\u001b[39mevaluate(val)\n",
      "File \u001b[1;32mc:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabular\\tabular_model.py:770\u001b[0m, in \u001b[0;36mTabularModel.fit\u001b[1;34m(self, train, validation, loss, metrics, metrics_prob_inputs, optimizer, optimizer_params, train_sampler, target_transform, max_epochs, min_epochs, seed, callbacks, datamodule, cache_data, handle_oom)\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m train \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    765\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    766\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain data and datamodule is provided.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    767\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Ignoring the train data and using the datamodule.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    768\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Set either one of them to None to avoid this warning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    769\u001b[0m         )\n\u001b[1;32m--> 770\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics_prob_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(model, datamodule, callbacks, max_epochs, min_epochs, handle_oom)\n",
      "File \u001b[1;32mc:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabular\\tabular_model.py:577\u001b[0m, in \u001b[0;36mTabularModel.prepare_model\u001b[1;34m(self, datamodule, loss, metrics, metrics_prob_inputs, optimizer, optimizer_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;66;03m# Fetching the config as some data specific configs have been added in the datamodule\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minferred_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_parse_config(datamodule\u001b[38;5;241m.\u001b[39mupdate_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig), InferredConfig)\n\u001b[1;32m--> 577\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_callable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Unused in SSL tasks\u001b[39;49;00m\n\u001b[0;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Unused in SSL tasks\u001b[39;49;00m\n\u001b[0;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metrics_prob_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics_prob_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Unused in SSL tasks\u001b[39;49;00m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_optimizer_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_params\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    584\u001b[0m \u001b[43m    \u001b[49m\u001b[43minferred_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minferred_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    585\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;66;03m# Data Aware Initialization(for the models that need it)\u001b[39;00m\n\u001b[0;32m    587\u001b[0m model\u001b[38;5;241m.\u001b[39mdata_aware_initialization(datamodule)\n",
      "File \u001b[1;32mc:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabular\\models\\tab_transformer\\tab_transformer.py:95\u001b[0m, in \u001b[0;36mTabTransformerModel.__init__\u001b[1;34m(self, config, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: DictConfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabular\\models\\base_model.py:147\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, config, custom_loss, custom_metrics, custom_metrics_prob_inputs, custom_optimizer, custom_optimizer_params, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;66;03m# The concatenated output dim of the embedding layer\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_network()\n\u001b[1;32m--> 147\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_metrics()\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_and_verify()\n",
      "File \u001b[1;32mc:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabular\\models\\base_model.py:205\u001b[0m, in \u001b[0;36mBaseModel._setup_loss\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    204\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid loss defined in the torch.nn module\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 205\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_loss\n",
      "File \u001b[1;32mc:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_tabular\\models\\base_model.py:202\u001b[0m, in \u001b[0;36mBaseModel._setup_loss\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 202\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m()\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    204\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid loss defined in the torch.nn module\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'mean_absolute_error'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,mean_absolute_percentage_error, r2_score\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.config import DataConfig, TrainerConfig, OptimizerConfig\n",
    "from pytorch_tabular.models import TabTransformerConfig\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"../data.zip\")\n",
    "X = data[data.columns[1:]]\n",
    "Y = data[data.columns[0]]\n",
    "\n",
    "# `num_col_names` lista con i nomi delle 89 colonne numeriche\n",
    "num_col_names = X.columns.tolist()\n",
    "\n",
    "# Split data\n",
    "seed = 89\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=seed, shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=seed, shuffle=True)  # 0.9 x 0.25 = 0.22 di validation\n",
    "\n",
    "# # Scaling dei dati MinMaxScaler()\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Creazione dei dataframe con target column in prima posizione\n",
    "train = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "train = pd.concat([y_train.reset_index(drop=True), train], axis=1)\n",
    "\n",
    "val = pd.DataFrame(X_val_scaled, columns=X.columns)\n",
    "val = pd.concat([y_val.reset_index(drop=True), val], axis=1)\n",
    "\n",
    "# Updated Configurations\n",
    "data_config = DataConfig(\n",
    "    target=[\"Year\"], \n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=[],\n",
    "    normalize_continuous_features=True #TODO: senza minmax mettere true --> fa standard scaler\n",
    ")\n",
    "\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=False,\n",
    "    batch_size=32, \n",
    "    max_epochs=150,\n",
    "    early_stopping_patience=10,\n",
    "    precision=32,\n",
    "    seed=seed\n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig(\n",
    "    optimizer=\"AdamW\"\n",
    ")\n",
    "\n",
    "model_config = TabTransformerConfig(\n",
    "    task=\"regression\",\n",
    "    learning_rate=0.00001,\n",
    "    num_heads=16,\n",
    "    num_attn_blocks=12,\n",
    "    ff_hidden_multiplier=12,\n",
    "    seed=seed,\n",
    "    metrics=[\"mean_squared_error\", \"mean_absolute_error\", \"mean_absolute_percentage_error\", \"r2_score\"],\n",
    "    attn_dropout=0.2,  # Added dropout for attention layers\n",
    "    embedding_dropout=0.2,  # Added dropout for embedding layers\n",
    ")\n",
    "\n",
    "# Initialize and train model\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "tabular_model.fit(train=train, validation=val, seed=seed)\n",
    "\n",
    "# Evaluate the model\n",
    "result = tabular_model.evaluate(val)\n",
    "print(result)\n",
    "\n",
    "# Make predictions\n",
    "pred_df = tabular_model.predict(test)\n",
    "print(pred_df)\n",
    "\n",
    "y_true = test['Year']\n",
    "y_pred = pred_df['Year_prediction']\n",
    "\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "r2score = r2_score(y_true, y_pred)\n",
    "print(\"MSE: \", mse, \" MAE:\", mae, \" MAPE:\", mape, \" R2_SCORE:\", r2score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
