{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installazione delle Librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: torch in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: pytorch-tabnet in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: pytorch-tabular in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gabriele\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: tqdm>=4.36 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-tabnet) (4.66.4)\n",
      "Requirement already satisfied: pytorch-lightning<2.2.0,>=2.0.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-tabular) (2.1.4)\n",
      "Requirement already satisfied: omegaconf>=2.3.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-tabular) (2.3.0)\n",
      "Requirement already satisfied: torchmetrics<1.3.0,>=0.10.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-tabular) (1.2.1)\n",
      "Requirement already satisfied: tensorboard!=2.5.0,>2.2.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-tabular) (2.16.2)\n",
      "Requirement already satisfied: protobuf<4.26.0,>=3.20.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-tabular) (4.25.3)\n",
      "Requirement already satisfied: PyYAML<6.1.0,>=5.4 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-tabular) (6.0.1)\n",
      "Requirement already satisfied: matplotlib>3.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-tabular) (3.9.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-tabular) (8.1.2)\n",
      "Requirement already satisfied: einops<0.8.0,>=0.6.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-tabular) (0.7.0)\n",
      "Requirement already satisfied: rich>=11.0.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-tabular) (13.7.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>3.1->pytorch-tabular) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>3.1->pytorch-tabular) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>3.1->pytorch-tabular) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>3.1->pytorch-tabular) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gabriele\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>3.1->pytorch-tabular) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>3.1->pytorch-tabular) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>3.1->pytorch-tabular) (3.1.2)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from omegaconf>=2.3.0->pytorch-tabular) (4.9.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gabriele\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytorch-lightning<2.2.0,>=2.0.0->pytorch-tabular) (0.11.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich>=11.0.0->pytorch-tabular) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\gabriele\\appdata\\roaming\\python\\python312\\site-packages (from rich>=11.0.0->pytorch-tabular) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (1.64.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (3.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (70.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard!=2.5.0,>2.2.0->pytorch-tabular) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\gabriele\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.36->pytorch-tabnet) (0.4.6)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\gabriele\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets->pytorch-tabular) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\gabriele\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets->pytorch-tabular) (8.24.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\gabriele\\appdata\\roaming\\python\\python312\\site-packages (from ipywidgets->pytorch-tabular) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipywidgets->pytorch-tabular) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from ipywidgets->pytorch-tabular) (3.0.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch-tabular) (3.9.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\gabriele\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets->pytorch-tabular) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\gabriele\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets->pytorch-tabular) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\gabriele\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets->pytorch-tabular) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\gabriele\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets->pytorch-tabular) (3.0.43)\n",
      "Requirement already satisfied: stack-data in c:\\users\\gabriele\\appdata\\roaming\\python\\python312\\site-packages (from ipython>=6.1.0->ipywidgets->pytorch-tabular) (0.6.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.0.0->pytorch-tabular) (0.1.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch-tabular) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch-tabular) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch-tabular) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch-tabular) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch-tabular) (1.9.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\gabriele\\appdata\\roaming\\python\\python312\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->pytorch-tabular) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\gabriele\\appdata\\roaming\\python\\python312\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets->pytorch-tabular) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\gabriele\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->pytorch-tabular) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\gabriele\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->pytorch-tabular) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\gabriele\\appdata\\roaming\\python\\python312\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets->pytorch-tabular) (0.2.2)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\gabriele\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning<2.2.0,>=2.0.0->pytorch-tabular) (3.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy pandas scikit-learn torch pytorch-tabnet pytorch-tabular joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import e definizioni delle funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.config import DataConfig, ModelConfig, OptimizerConfig, TrainerConfig\n",
    "import joblib\n",
    "\n",
    "random_state = 89\n",
    "\n",
    "def save_model(model, filename):\n",
    "    joblib.dump(model, f'{filename}.pkl')\n",
    "\n",
    "def preprocess(X, scaler_type='standard', use_pca=False, n_components=None):\n",
    "    if scaler_type == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler_type == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    pca = None\n",
    "    if use_pca and n_components:\n",
    "        pca = PCA(n_components=n_components, random_state=random_state)\n",
    "        X_scaled = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    return X_scaled, scaler, pca\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caricamento dei Dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# CSV zip folder's path\n",
    "csv_file_name = '../data.zip'\n",
    "\n",
    "# loading data from csv\n",
    "df = pd.read_csv(csv_file_name)\n",
    "\n",
    "X = df.drop(columns='Year')\n",
    "y = df['Year']\n",
    "\n",
    "# Suddividi i dati in training e validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funzioni di Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per addestrare i modelli tradizionali\n",
    "def train_model(X_train, y_train, model_type='LR'):\n",
    "    if model_type == 'LR':\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        best_params = None\n",
    "    elif model_type == 'RF':\n",
    "        model = RandomForestRegressor(random_state=random_state)\n",
    "        model.fit(X_train, y_train)\n",
    "        best_params = None\n",
    "    elif model_type == 'KNR':\n",
    "        model = KNeighborsRegressor()\n",
    "        model.fit(X_train, y_train)\n",
    "        best_params = None\n",
    "    elif model_type == 'SVR':\n",
    "        model = SVR()\n",
    "        model.fit(X_train, y_train)\n",
    "        best_params = None\n",
    "    return model, best_params\n",
    "\n",
    "# Funzione per addestrare la rete neurale feed-forward\n",
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 64)\n",
    "        self.layer2 = nn.Linear(64, 64)\n",
    "        self.layer3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "def train_ffnn(X_train, y_train, input_dim):\n",
    "    model = FeedForwardNN(input_dim)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "    \n",
    "    for epoch in range(100):  # Number of epochs can be adjusted\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Funzione per addestrare TabNet\n",
    "def train_tabnet(X_train, y_train, X_val, y_val):\n",
    "    tabnet = TabNetRegressor(verbose=1, seed=random_state)\n",
    "    tabnet.fit(X_train, y_train, eval_set=[(X_val, y_val)], patience=50, max_epochs=1000)\n",
    "    return tabnet\n",
    "\n",
    "# Funzione per addestrare TabTransformer\n",
    "def train_tabtransformer(df_train, df_val, target_col='Year'):\n",
    "    data_config = DataConfig(\n",
    "        target=target_col,\n",
    "        continuous_cols=df_train.columns.drop(target_col).tolist()\n",
    "    )\n",
    "    model_config = ModelConfig(\n",
    "        task=\"regression\",\n",
    "        learning_rate=1e-3,\n",
    "        seed=random_state\n",
    "    )\n",
    "    trainer_config = TrainerConfig(\n",
    "        max_epochs=100,\n",
    "        gpus=1 if torch.cuda.is_available() else 0\n",
    "    )\n",
    "    tabular_model = TabularModel(\n",
    "        data_config=data_config,\n",
    "        model_config=model_config,\n",
    "        optimizer_config=OptimizerConfig(),\n",
    "        trainer_config=trainer_config\n",
    "    )\n",
    "    tabular_model.fit(train=df_train, validation=df_val)\n",
    "    return tabular_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing e salvataggio dei risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esegui il preprocessing specifico per ogni modello con Standard Scaler e Min-Max Scaler\n",
    "preprocessing_options = {\n",
    "    'LR': {'scaler_type': ['standard', 'minmax'], 'use_pca': [True, False], 'n_components': 52},\n",
    "    'RF': {'scaler_type': ['standard', 'minmax'], 'use_pca': [True, False], 'n_components': 52},\n",
    "    'KNR': {'scaler_type': ['standard', 'minmax'], 'use_pca': [True, False], 'n_components': 52},\n",
    "    'SVR': {'scaler_type': ['standard', 'minmax'], 'use_pca': [True, False], 'n_components': 52},\n",
    "    'FFNN': {'scaler_type': ['standard', 'minmax'], 'use_pca': [True, False], 'n_components': 52},\n",
    "    'TabNet': {'scaler_type': ['standard', 'minmax'], 'use_pca': [False], 'n_components': None},\n",
    "    'TabTransformer': {'scaler_type': ['standard', 'minmax'], 'use_pca': [False], 'n_components': None},\n",
    "}\n",
    "\n",
    "# Funzione per eseguire il preprocessing e salvare i risultati\n",
    "def preprocess_and_save(X_train, X_val, preprocessing_options):\n",
    "    scalers = {}\n",
    "    pcas = {}\n",
    "    for clfName, options in preprocessing_options.items():\n",
    "        for scaler_type in options['scaler_type']:\n",
    "            for use_pca in options['use_pca']:\n",
    "                key = f\"{clfName}_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "                X_train_scaled, scaler, pca = preprocess(X_train, scaler_type=scaler_type, use_pca=use_pca, n_components=options['n_components'])\n",
    "                X_val_scaled = scaler.transform(X_val)\n",
    "                if pca:\n",
    "                    X_val_scaled = pca.transform(X_val_scaled)\n",
    "                scalers[key] = scaler\n",
    "                pcas[key] = pca\n",
    "                save_model(scaler, f'scaler_{key.lower()}')\n",
    "                if pca:\n",
    "                    save_model(pca, f'pca_{key.lower()}')\n",
    "    return scalers, pcas\n",
    "\n",
    "# Esegui il preprocessing per tutte le combinazioni di scaler e PCA\n",
    "scalers, pcas = preprocess_and_save(X_train, X_val, preprocessing_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training trad models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All the models (DO NOT run this cell if you don't want your PC to crash or to explode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestra i modelli tradizionali con tutte le combinazioni di scaler e PCA\n",
    "models = {}\n",
    "for clfName in ['LR', 'RF', 'KNR', 'SVR']:\n",
    "    for scaler_type in preprocessing_options[clfName]['scaler_type']:\n",
    "        for use_pca in preprocessing_options[clfName]['use_pca']:\n",
    "            key = f\"{clfName}_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "            X_train_scaled = scalers[key].transform(X_train)\n",
    "            if pcas[key]:\n",
    "                X_train_scaled = pcas[key].transform(X_train_scaled)\n",
    "            model, params = train_model(X_train_scaled, y_train, model_type=clfName)\n",
    "            models[key] = model\n",
    "            save_model(model, f'model_{clfName.lower()}_{scaler_type}_{\"pca\" if use_pca else \"nopca\"}')\n",
    "            print(f\"Trained {clfName} with {scaler_type} scaler and PCA={use_pca}, parameters: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "performance = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained LR with standard scaler and PCA=True, parameters: None\n",
      "Trained LR with standard scaler and PCA=False, parameters: None\n",
      "Trained LR with minmax scaler and PCA=True, parameters: None\n",
      "Trained LR with minmax scaler and PCA=False, parameters: None\n"
     ]
    }
   ],
   "source": [
    "# Addestra i modelli tradizionali con tutte le combinazioni di scaler e PCA\n",
    "# models = {}\n",
    "clfName = 'LR'\n",
    "for scaler_type in preprocessing_options[clfName]['scaler_type']:\n",
    "    for use_pca in preprocessing_options[clfName]['use_pca']:\n",
    "        key = f\"{clfName}_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "        X_train_scaled = scalers[key].transform(X_train)\n",
    "        if pcas[key]:\n",
    "            X_train_scaled = pcas[key].transform(X_train_scaled)\n",
    "        model, params = train_model(X_train_scaled, y_train, model_type=clfName)\n",
    "        models[key] = model\n",
    "        save_model(model, f'model_{clfName.lower()}_{scaler_type}_{\"pca\" if use_pca else \"nopca\"}')\n",
    "        print(f\"Trained {clfName} with {scaler_type} scaler and PCA={use_pca}, parameters: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained RF with standard scaler and PCA=True, parameters: None\n",
      "Trained RF with standard scaler and PCA=False, parameters: None\n",
      "Trained RF with minmax scaler and PCA=True, parameters: None\n",
      "Trained RF with minmax scaler and PCA=False, parameters: None\n"
     ]
    }
   ],
   "source": [
    "# Addestra i modelli tradizionali con tutte le combinazioni di scaler e PCA\n",
    "# models = {}\n",
    "clfName = 'RF'\n",
    "for scaler_type in preprocessing_options[clfName]['scaler_type']:\n",
    "    for use_pca in preprocessing_options[clfName]['use_pca']:\n",
    "        key = f\"{clfName}_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "        X_train_scaled = scalers[key].transform(X_train)\n",
    "        if pcas[key]:\n",
    "            X_train_scaled = pcas[key].transform(X_train_scaled)\n",
    "        model, params = train_model(X_train_scaled, y_train, model_type=clfName)\n",
    "        models[key] = model\n",
    "        save_model(model, f'model_{clfName.lower()}_{scaler_type}_{\"pca\" if use_pca else \"nopca\"}')\n",
    "        print(f\"Trained {clfName} with {scaler_type} scaler and PCA={use_pca}, parameters: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training KNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained KNR with standard scaler and PCA=True, parameters: None\n",
      "Trained KNR with standard scaler and PCA=False, parameters: None\n",
      "Trained KNR with minmax scaler and PCA=True, parameters: None\n",
      "Trained KNR with minmax scaler and PCA=False, parameters: None\n"
     ]
    }
   ],
   "source": [
    "# Addestra i modelli tradizionali con tutte le combinazioni di scaler e PCA\n",
    "# models = {}\n",
    "clfName = 'KNR'\n",
    "for scaler_type in preprocessing_options[clfName]['scaler_type']:\n",
    "    for use_pca in preprocessing_options[clfName]['use_pca']:\n",
    "        key = f\"{clfName}_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "        X_train_scaled = scalers[key].transform(X_train)\n",
    "        if pcas[key]:\n",
    "            X_train_scaled = pcas[key].transform(X_train_scaled)\n",
    "        model, params = train_model(X_train_scaled, y_train, model_type=clfName)\n",
    "        models[key] = model\n",
    "        save_model(model, f'model_{clfName.lower()}_{scaler_type}_{\"pca\" if use_pca else \"nopca\"}')\n",
    "        print(f\"Trained {clfName} with {scaler_type} scaler and PCA={use_pca}, parameters: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained SVR with standard scaler and PCA=True, parameters: None\n",
      "Trained SVR with standard scaler and PCA=False, parameters: None\n",
      "Trained SVR with minmax scaler and PCA=True, parameters: None\n",
      "Trained SVR with minmax scaler and PCA=False, parameters: None\n"
     ]
    }
   ],
   "source": [
    "# Addestra i modelli tradizionali con tutte le combinazioni di scaler e PCA\n",
    "# models = {}\n",
    "clfName = 'SVR'\n",
    "for scaler_type in preprocessing_options[clfName]['scaler_type']:\n",
    "    for use_pca in preprocessing_options[clfName]['use_pca']:\n",
    "        key = f\"{clfName}_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "        X_train_scaled = scalers[key].transform(X_train)\n",
    "        if pcas[key]:\n",
    "            X_train_scaled = pcas[key].transform(X_train_scaled)\n",
    "        model, params = train_model(X_train_scaled, y_train, model_type=clfName)\n",
    "        models[key] = model\n",
    "        save_model(model, f'model_{clfName.lower()}_{scaler_type}_{\"pca\" if use_pca else \"nopca\"}')\n",
    "        print(f\"Trained {clfName} with {scaler_type} scaler and PCA={use_pca}, parameters: {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained FFNN with standard scaler and PCA=True\n",
      "Trained FFNN with standard scaler and PCA=False\n",
      "Trained FFNN with minmax scaler and PCA=True\n",
      "Trained FFNN with minmax scaler and PCA=False\n"
     ]
    }
   ],
   "source": [
    "# Addestra il modello FFNN con tutte le combinazioni di scaler e PCA\n",
    "for scaler_type in preprocessing_options['FFNN']['scaler_type']:\n",
    "    for use_pca in preprocessing_options['FFNN']['use_pca']:\n",
    "        key = f\"FFNN_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "        X_train_scaled = scalers[key].transform(X_train)\n",
    "        if pcas[key]:\n",
    "            X_train_scaled = pcas[key].transform(X_train_scaled)\n",
    "        ffnn_model = train_ffnn(X_train_scaled, y_train, input_dim=X_train_scaled.shape[1])\n",
    "        models[key] = ffnn_model\n",
    "        save_model(ffnn_model, f'model_ffnn_{scaler_type}_{\"pca\" if use_pca else \"nopca\"}')\n",
    "        print(f\"Trained FFNN with {scaler_type} scaler and PCA={use_pca}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Targets should be 2D : (n_samples, n_regression) but y_train.shape=(201740,) given.\nUse reshape(-1, 1) for single regression.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m scalers[key]\u001b[38;5;241m.\u001b[39mtransform(X_train)\n\u001b[0;32m      5\u001b[0m X_val_scaled \u001b[38;5;241m=\u001b[39m scalers[key]\u001b[38;5;241m.\u001b[39mtransform(X_val)\n\u001b[1;32m----> 6\u001b[0m tabnet_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_tabnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m models[key] \u001b[38;5;241m=\u001b[39m tabnet_model\n\u001b[0;32m      8\u001b[0m save_model(tabnet_model, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_tabnet_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscaler_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 56\u001b[0m, in \u001b[0;36mtrain_tabnet\u001b[1;34m(X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_tabnet\u001b[39m(X_train, y_train, X_val, y_val):\n\u001b[0;32m     55\u001b[0m     tabnet \u001b[38;5;241m=\u001b[39m TabNetRegressor(verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, seed\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m---> 56\u001b[0m     \u001b[43mtabnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tabnet\n",
      "File \u001b[1;32mc:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\abstract_model.py:220\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[1;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[0;32m    217\u001b[0m check_input(X_train)\n\u001b[0;32m    218\u001b[0m check_warm_start(warm_start, from_unsupervised)\n\u001b[1;32m--> 220\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_fit_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# Validate and reformat eval set depending on training data\u001b[39;00m\n\u001b[0;32m    228\u001b[0m eval_names, eval_set \u001b[38;5;241m=\u001b[39m validate_eval_set(eval_set, eval_name, X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\Gabriele\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pytorch_tabnet\\tab_model.py:141\u001b[0m, in \u001b[0;36mTabNetRegressor.update_fit_params\u001b[1;34m(self, X_train, y_train, eval_set, weights)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_train\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    138\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTargets should be 2D : (n_samples, n_regression) \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m    139\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut y_train.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m given.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m    140\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse reshape(-1, 1) for single regression.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreds_mapper \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Targets should be 2D : (n_samples, n_regression) but y_train.shape=(201740,) given.\nUse reshape(-1, 1) for single regression."
     ]
    }
   ],
   "source": [
    "# Addestra il modello TabNet (solo senza PCA)\n",
    "for scaler_type in preprocessing_options['TabNet']['scaler_type']:\n",
    "    key = f\"TabNet_{scaler_type}_NoPCA\"\n",
    "    X_train_scaled = scalers[key].transform(X_train)\n",
    "    X_val_scaled = scalers[key].transform(X_val)\n",
    "    tabnet_model = train_tabnet(X_train_scaled, y_train, X_val_scaled, y_val)\n",
    "    models[key] = tabnet_model\n",
    "    save_model(tabnet_model, f'model_tabnet_{scaler_type}')\n",
    "    print(f\"Trained TabNet with {scaler_type} scaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training TabTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TrainerConfig.__init__() got an unexpected keyword argument 'gpus'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scaler_type \u001b[38;5;129;01min\u001b[39;00m preprocessing_options[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTabTransformer\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler_type\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      6\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTabTransformer_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscaler_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_NoPCA\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m     tabtransformer_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_tabtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     models[key] \u001b[38;5;241m=\u001b[39m tabtransformer_model\n\u001b[0;32m      9\u001b[0m     save_model(tabtransformer_model, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_tabtransformer_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscaler_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 70\u001b[0m, in \u001b[0;36mtrain_tabtransformer\u001b[1;34m(df_train, df_val, target_col)\u001b[0m\n\u001b[0;32m     61\u001b[0m data_config \u001b[38;5;241m=\u001b[39m DataConfig(\n\u001b[0;32m     62\u001b[0m     target\u001b[38;5;241m=\u001b[39mtarget_col,\n\u001b[0;32m     63\u001b[0m     continuous_cols\u001b[38;5;241m=\u001b[39mdf_train\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdrop(target_col)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     65\u001b[0m model_config \u001b[38;5;241m=\u001b[39m ModelConfig(\n\u001b[0;32m     66\u001b[0m     task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     67\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m,\n\u001b[0;32m     68\u001b[0m     seed\u001b[38;5;241m=\u001b[39mrandom_state\n\u001b[0;32m     69\u001b[0m )\n\u001b[1;32m---> 70\u001b[0m trainer_config \u001b[38;5;241m=\u001b[39m \u001b[43mTrainerConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m     73\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m tabular_model \u001b[38;5;241m=\u001b[39m TabularModel(\n\u001b[0;32m     75\u001b[0m     data_config\u001b[38;5;241m=\u001b[39mdata_config,\n\u001b[0;32m     76\u001b[0m     model_config\u001b[38;5;241m=\u001b[39mmodel_config,\n\u001b[0;32m     77\u001b[0m     optimizer_config\u001b[38;5;241m=\u001b[39mOptimizerConfig(),\n\u001b[0;32m     78\u001b[0m     trainer_config\u001b[38;5;241m=\u001b[39mtrainer_config\n\u001b[0;32m     79\u001b[0m )\n\u001b[0;32m     80\u001b[0m tabular_model\u001b[38;5;241m.\u001b[39mfit(train\u001b[38;5;241m=\u001b[39mdf_train, validation\u001b[38;5;241m=\u001b[39mdf_val)\n",
      "\u001b[1;31mTypeError\u001b[0m: TrainerConfig.__init__() got an unexpected keyword argument 'gpus'"
     ]
    }
   ],
   "source": [
    "# Addestra il modello TabTransformer (solo senza PCA)\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "df_val = pd.concat([X_val, y_val], axis=1)\n",
    "\n",
    "for scaler_type in preprocessing_options['TabTransformer']['scaler_type']:\n",
    "    key = f\"TabTransformer_{scaler_type}_NoPCA\"\n",
    "    tabtransformer_model = train_tabtransformer(df_train, df_val, target_col='Year')\n",
    "    models[key] = tabtransformer_model\n",
    "    save_model(tabtransformer_model, f'model_tabtransformer_{scaler_type}')\n",
    "    print(f\"Trained TabTransformer with {scaler_type} scaler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All the models (DO NOT run this cell if you don't want your PC to crash or to explode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione dei modelli con tutte le combinazioni di scaler e PCA\n",
    "# performance = {}\n",
    "\n",
    "# Valutazione modelli tradizionali\n",
    "for clfName in ['LR', 'RF', 'KNR', 'SVR']:\n",
    "    for scaler_type in preprocessing_options[clfName]['scaler_type']:\n",
    "        for use_pca in preprocessing_options[clfName]['use_pca']:\n",
    "            key = f\"{clfName}_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "            X_val_scaled = scalers[key].transform(X_val)\n",
    "            if pcas[key]:\n",
    "                X_val_scaled = pcas[key].transform(X_val_scaled)\n",
    "            y_pred = models[key].predict(X_val_scaled)\n",
    "            mse = mean_squared_error(y_val, y_pred)\n",
    "            mae = mean_absolute_error(y_val, y_pred)\n",
    "            r2 = r2_score(y_val, y_pred)\n",
    "            performance[key] = {'mse': mse, 'mae': mae, 'r2': r2}\n",
    "            print(f\"Performance of {clfName} with {scaler_type} scaler and PCA={use_pca}: MSE={mse}, MAE={mae}, R2={r2}\")\n",
    "\n",
    "# Valutazione FFNN\n",
    "for scaler_type in preprocessing_options['FFNN']['scaler_type']:\n",
    "    for use_pca in preprocessing_options['FFNN']['use_pca']:\n",
    "        key = f\"FFNN_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "        X_val_scaled = scalers[key].transform(X_val)\n",
    "        if pcas[key]:\n",
    "            X_val_scaled = pcas[key].transform(X_val_scaled)\n",
    "        X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "        y_pred_tensor = models[key](X_val_tensor).detach().numpy().squeeze()\n",
    "        mse = mean_squared_error(y_val, y_pred_tensor)\n",
    "        mae = mean_absolute_error(y_val, y_pred_tensor)\n",
    "        r2 = r2_score(y_val, y_pred_tensor)\n",
    "        performance[key] = {'mse': mse, 'mae': mae, 'r2': r2}\n",
    "        print(f\"Performance of FFNN with {scaler_type} scaler and PCA={use_pca}: MSE={mse}, MAE={mae}, R2={r2}\")\n",
    "\n",
    "# Valutazione TabNet\n",
    "for scaler_type in preprocessing_options['TabNet']['scaler_type']:\n",
    "    key = f\"TabNet_{scaler_type}_NoPCA\"\n",
    "    X_val_scaled = scalers[key].transform(X_val)\n",
    "    y_pred = models[key].predict(X_val_scaled)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    performance[key] = {'mse': mse, 'mae': mae, 'r2': r2}\n",
    "    print(f\"Performance of TabNet with {scaler_type} scaler: MSE={mse}, MAE={mae}, R2={r2}\")\n",
    "\n",
    "# Valutazione TabTransformer\n",
    "for scaler_type in preprocessing_options['TabTransformer']['scaler_type']:\n",
    "    key = f\"TabTransformer_{scaler_type}_NoPCA\"\n",
    "    y_pred = models[key].predict(df_val).squeeze()\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    performance[key] = {'mse': mse, 'mae': mae, 'r2': r2}\n",
    "    print(f\"Performance of TabTransformer with {scaler_type} scaler: MSE={mse}, MAE={mae}, R2={r2}\")\n",
    "\n",
    "# Salva le performance dei modelli\n",
    "with open('performance.txt', 'w') as f:\n",
    "    for clfName, metrics in performance.items():\n",
    "        f.write(f\"{clfName}: MSE={metrics['mse']}, MAE={metrics['mae']}, R2={metrics['r2']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of LR with standard scaler and PCA=True: MSE=98.2318351539259, MAE=7.392438758148582, R2=0.12050186127982243\n",
      "Performance of LR with standard scaler and PCA=False: MSE=85.58234834475938, MAE=6.668881118801984, R2=0.23375638907108864\n",
      "Performance of LR with minmax scaler and PCA=True: MSE=87.21013510994777, MAE=6.73281651718109, R2=0.21918234158461758\n",
      "Performance of LR with minmax scaler and PCA=False: MSE=85.58234834475938, MAE=6.668881118801991, R2=0.23375638907108864\n"
     ]
    }
   ],
   "source": [
    "# Valutazione dei modelli con tutte le combinazioni di scaler e PCA\n",
    "# performance = {}\n",
    "\n",
    "# Valutazione modelli tradizionali\n",
    "for clfName in ['LR']:\n",
    "    for scaler_type in preprocessing_options[clfName]['scaler_type']:\n",
    "        for use_pca in preprocessing_options[clfName]['use_pca']:\n",
    "            key = f\"{clfName}_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "            X_val_scaled = scalers[key].transform(X_val)\n",
    "            if pcas[key]:\n",
    "                X_val_scaled = pcas[key].transform(X_val_scaled)\n",
    "            y_pred = models[key].predict(X_val_scaled)\n",
    "            mse = mean_squared_error(y_val, y_pred)\n",
    "            mae = mean_absolute_error(y_val, y_pred)\n",
    "            r2 = r2_score(y_val, y_pred)\n",
    "            performance[key] = {'mse': mse, 'mae': mae, 'r2': r2}\n",
    "            print(f\"Performance of {clfName} with {scaler_type} scaler and PCA={use_pca}: MSE={mse}, MAE={mae}, R2={r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation RF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of RF with standard scaler and PCA=True: MSE=92.01214625373923, MAE=7.210540541101935, R2=0.17618854169825393\n",
      "Performance of RF with standard scaler and PCA=False: MSE=79.40827703444918, MAE=6.436896507055287, R2=0.2890346419636943\n",
      "Performance of RF with minmax scaler and PCA=True: MSE=81.65413718735886, MAE=6.573940451406099, R2=0.26892680399838764\n",
      "Performance of RF with minmax scaler and PCA=False: MSE=79.42058209449787, MAE=6.438306572816495, R2=0.28892447118868336\n"
     ]
    }
   ],
   "source": [
    "# Valutazione dei modelli con tutte le combinazioni di scaler e PCA\n",
    "performance = {}\n",
    "\n",
    "# Valutazione modelli tradizionali\n",
    "for clfName in ['RF']:\n",
    "    for scaler_type in preprocessing_options[clfName]['scaler_type']:\n",
    "        for use_pca in preprocessing_options[clfName]['use_pca']:\n",
    "            key = f\"{clfName}_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "            X_val_scaled = scalers[key].transform(X_val)\n",
    "            if pcas[key]:\n",
    "                X_val_scaled = pcas[key].transform(X_val_scaled)\n",
    "            y_pred = models[key].predict(X_val_scaled)\n",
    "            mse = mean_squared_error(y_val, y_pred)\n",
    "            mae = mean_absolute_error(y_val, y_pred)\n",
    "            r2 = r2_score(y_val, y_pred)\n",
    "            performance[key] = {'mse': mse, 'mae': mae, 'r2': r2}\n",
    "            print(f\"Performance of {clfName} with {scaler_type} scaler and PCA={use_pca}: MSE={mse}, MAE={mae}, R2={r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation KNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of KNR with standard scaler and PCA=True: MSE=95.77045226529194, MAE=7.149356597600872, R2=0.14253933686845544\n",
      "Performance of KNR with standard scaler and PCA=False: MSE=89.67204282740155, MAE=6.853474769505305, R2=0.19714016705119275\n",
      "Performance of KNR with minmax scaler and PCA=True: MSE=85.17326063249726, MAE=6.556490532368397, R2=0.23741907012498586\n",
      "Performance of KNR with minmax scaler and PCA=False: MSE=84.66267790225041, MAE=6.556375532864084, R2=0.24199046554085202\n"
     ]
    }
   ],
   "source": [
    "# Valutazione modelli tradizionali\n",
    "for clfName in ['KNR']:\n",
    "    for scaler_type in preprocessing_options[clfName]['scaler_type']:\n",
    "        for use_pca in preprocessing_options[clfName]['use_pca']:\n",
    "            key = f\"{clfName}_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "            X_val_scaled = scalers[key].transform(X_val)\n",
    "            if pcas[key]:\n",
    "                X_val_scaled = pcas[key].transform(X_val_scaled)\n",
    "            y_pred = models[key].predict(X_val_scaled)\n",
    "            mse = mean_squared_error(y_val, y_pred)\n",
    "            mae = mean_absolute_error(y_val, y_pred)\n",
    "            r2 = r2_score(y_val, y_pred)\n",
    "            performance[key] = {'mse': mse, 'mae': mae, 'r2': r2}\n",
    "            print(f\"Performance of {clfName} with {scaler_type} scaler and PCA={use_pca}: MSE={mse}, MAE={mae}, R2={r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of SVR with standard scaler and PCA=True: MSE=89.76062511715364, MAE=6.356003295928954, R2=0.19634706409390346\n"
     ]
    }
   ],
   "source": [
    "# Valutazione modelli tradizionali\n",
    "for clfName in ['SVR']:\n",
    "    for scaler_type in preprocessing_options[clfName]['scaler_type']:\n",
    "        for use_pca in preprocessing_options[clfName]['use_pca']:\n",
    "            key = f\"{clfName}_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "            X_val_scaled = scalers[key].transform(X_val)\n",
    "            if pcas[key]:\n",
    "                X_val_scaled = pcas[key].transform(X_val_scaled)\n",
    "            y_pred = models[key].predict(X_val_scaled)\n",
    "            mse = mean_squared_error(y_val, y_pred)\n",
    "            mae = mean_absolute_error(y_val, y_pred)\n",
    "            r2 = r2_score(y_val, y_pred)\n",
    "            performance[key] = {'mse': mse, 'mae': mae, 'r2': r2}\n",
    "            print(f\"Performance of {clfName} with {scaler_type} scaler and PCA={use_pca}: MSE={mse}, MAE={mae}, R2={r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation FFNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione FFNN\n",
    "for scaler_type in preprocessing_options['FFNN']['scaler_type']:\n",
    "    for use_pca in preprocessing_options['FFNN']['use_pca']:\n",
    "        key = f\"FFNN_{scaler_type}_{'PCA' if use_pca else 'NoPCA'}\"\n",
    "        X_val_scaled = scalers[key].transform(X_val)\n",
    "        if pcas[key]:\n",
    "            X_val_scaled = pcas[key].transform(X_val_scaled)\n",
    "        X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "        y_pred_tensor = models[key](X_val_tensor).detach().numpy().squeeze()\n",
    "        mse = mean_squared_error(y_val, y_pred_tensor)\n",
    "        mae = mean_absolute_error(y_val, y_pred_tensor)\n",
    "        r2 = r2_score(y_val, y_pred_tensor)\n",
    "        performance[key] = {'mse': mse, 'mae': mae, 'r2': r2}\n",
    "        print(f\"Performance of FFNN with {scaler_type} scaler and PCA={use_pca}: MSE={mse}, MAE={mae}, R2={r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation TabNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione TabNet\n",
    "for scaler_type in preprocessing_options['TabNet']['scaler_type']:\n",
    "    key = f\"TabNet_{scaler_type}_NoPCA\"\n",
    "    X_val_scaled = scalers[key].transform(X_val)\n",
    "    y_pred = models[key].predict(X_val_scaled)\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    performance[key] = {'mse': mse, 'mae': mae, 'r2': r2}\n",
    "    print(f\"Performance of TabNet with {scaler_type} scaler: MSE={mse}, MAE={mae}, R2={r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation TabTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione TabTransformer\n",
    "for scaler_type in preprocessing_options['TabTransformer']['scaler_type']:\n",
    "    key = f\"TabTransformer_{scaler_type}_NoPCA\"\n",
    "    y_pred = models[key].predict(df_val).squeeze()\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    performance[key] = {'mse': mse, 'mae': mae, 'r2': r2}\n",
    "    print(f\"Performance of TabTransformer with {scaler_type} scaler: MSE={mse}, MAE={mae}, R2={r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Salva le performance dei modelli\n",
    "with open('performance.txt', 'w') as f:\n",
    "    for clfName, metrics in performance.items():\n",
    "        f.write(f\"{clfName}: MSE={metrics['mse']}, MAE={metrics['mae']}, R2={metrics['r2']}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
