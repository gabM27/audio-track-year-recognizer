{"cells":[{"cell_type":"markdown","metadata":{"id":"a6uFyzswP6ph"},"source":["# Main Script\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Lo9t2JfUP6pj"},"source":["#### Needed Imports"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#to install the complete library with extra dependencies (Weights&Biases & Plotly). (TabNet)\n","%pip install -U pytorch_tabular"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":105770,"status":"ok","timestamp":1707045350449,"user":{"displayName":"Andrea Bianchi","userId":"00641891010832459678"},"user_tz":-60},"id":"2n5yTTlLP6pj","outputId":"5b8958a0-be20-41bf-c650-1e18b74a7fc4"},"outputs":[],"source":["#Installo le librerie\n","%pip install -U seaborn\n","%pip install --upgrade keras\n","#%pip install --upgrade tensorflow\n","%pip install --upgrade tensorboard\n","#%pip install torch torchvision torchaudio #Only CPU\n","%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 #CUDA 11.8\n","%pip install --upgrade Pillow\n","\n","# %pip install --upgrade pip setuptools wheel #Aggiorna i pacchetti e Python, ma ci mette troppo."]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":13488,"status":"ok","timestamp":1707045363933,"user":{"displayName":"Andrea Bianchi","userId":"00641891010832459678"},"user_tz":-60},"id":"a2pcwV8xsTrR"},"outputs":[],"source":["#Import delle Librerie\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from scipy.stats import iqr\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.decomposition import PCA\n","from sklearn.linear_model import LinearRegression\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import mean_squared_error,mean_absolute_error, r2_score\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.svm import SVR\n","import scipy.stats as stats\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n","# import tensorflow as tf\n","# from tensorflow import keras\n","# from keras.layers import Dense\n","# from keras.models import Sequential\n","# from tensorflow.keras.callbacks import ModelCheckpoint\n","from sklearn.neighbors import NeighborhoodComponentsAnalysis\n","from sklearn.model_selection import train_test_split\n","import pickle\n","import random\n","import os\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader, Subset\n","from torch.utils.tensorboard import SummaryWriter\n","from sklearn.model_selection import learning_curve\n","from sklearn.metrics import accuracy_score,make_scorer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.feature_selection import RFE"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23253,"status":"ok","timestamp":1707045387183,"user":{"displayName":"Andrea Bianchi","userId":"00641891010832459678"},"user_tz":-60},"id":"om_EDTe_oO3b","outputId":"41a65ebf-8d97-43f3-bfe3-d901f32ab0c6"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"ZXCTdel4P6pj"},"source":["#### Loading data from data_loader.py"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# CSV zip folder's path\n","csv_file_name = '../data.zip'\n","\n","# loading data from csv\n","data = pd.read_csv(csv_file_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11543,"status":"ok","timestamp":1707045398722,"user":{"displayName":"Andrea Bianchi","userId":"00641891010832459678"},"user_tz":-60},"id":"gmKG_i9eP6pk"},"outputs":[],"source":["# CSV zip folder's path\n","csv_file_name = '/content/drive/MyDrive/Colab Notebooks/data.zip'\n","\n","# loading data from csv\n","data = pd.read_csv(csv_file_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1707045398722,"user":{"displayName":"Andrea Bianchi","userId":"00641891010832459678"},"user_tz":-60},"id":"SMjsx7V84m6y","outputId":"3e84dd72-2153-40d1-86b9-3db4c7fa4de7"},"outputs":[],"source":["len(data)"]},{"cell_type":"markdown","metadata":{"id":"S2t_JI80P6pk"},"source":["---\n","#### Data Acquisition"]},{"cell_type":"markdown","metadata":{"id":"0uJgAncSP6pk"},"source":["#### Describing data"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1086,"status":"ok","timestamp":1707045399804,"user":{"displayName":"Andrea Bianchi","userId":"00641891010832459678"},"user_tz":-60},"id":"eghtPkbnP6pk","outputId":"f1f1c137-7dbf-47e5-f5f1-f36f3cc14950"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset shape: (252175, 91)\n","                  S0             S1             S2             S3   \n","count  252175.000000  252175.000000  252175.000000  252175.000000  \\\n","mean       43.379379       1.555258       8.643927       1.160078   \n","std         6.066547      51.551085      35.235495      16.336577   \n","min         3.455260    -334.953220    -301.005060    -149.962040   \n","25%        39.959775     -25.651750     -11.524900      -8.492585   \n","50%        44.250440       8.655610      10.516440      -0.641920   \n","75%        47.822515      36.248650      29.792790       8.766685   \n","max        61.970140     384.065730     318.868960     228.412110   \n","\n","                  S4             S5             S6             S7   \n","count  252175.000000  252175.000000  252175.000000  252175.000000  \\\n","mean       -6.526075      -9.532049      -2.366866      -1.788645   \n","std        22.841967      12.809154      14.530697       7.963275   \n","min      -181.953370     -72.717370    -111.017810     -68.404510   \n","25%       -20.587910     -18.402445     -10.770340      -6.472825   \n","50%        -5.999260     -11.189750      -2.072920      -1.727900   \n","75%         7.739900      -2.448645       6.512925       2.913400   \n","max       262.068870     166.236890     160.815220      82.942190   \n","\n","                  S8             S9  ...            S80            S81   \n","count  252175.000000  252175.000000  ...  252175.000000  252175.000000  \\\n","mean        3.713079       1.885508  ...      15.723383     -73.290415   \n","std        10.553843       6.518473  ...      31.982900     174.935574   \n","min      -119.762620     -38.235830  ...    -437.722030   -2984.920970   \n","25%        -2.295965      -2.441000  ...      -1.788255    -139.034460   \n","50%         3.821990       1.785010  ...       9.132400     -53.168610   \n","75%         9.938425       6.142600  ...      26.206820      13.411780   \n","max        92.792850      60.345350  ...     840.973380    4469.454870   \n","\n","                 S82            S83            S84            S85   \n","count  252175.000000  252175.000000  252175.000000  252175.000000  \\\n","mean       41.480537      38.046821       0.334712      17.927021   \n","std       122.250383      94.576578      16.020922     114.053576   \n","min     -1810.689190   -1848.702260    -272.289050   -2343.894110   \n","25%       -21.014560      -4.630075      -6.748720     -31.246970   \n","50%        28.673440      33.597330       0.819000      15.843510   \n","75%        89.181345      77.881735       8.452415      67.776640   \n","max      3210.701700    1734.079690     199.121500    3662.065650   \n","\n","                 S86            S87            S88            S89  \n","count  252175.000000  252175.000000  252175.000000  252175.000000  \n","mean      -26.502617       4.487977      19.875335       1.309523  \n","std       173.680285      13.286064     185.158800      22.113525  \n","min     -3819.933620    -233.456480   -7458.378150    -286.031200  \n","25%      -102.175470      -2.536810     -59.734690      -8.820370  \n","50%       -21.613560       3.145290       7.774840       0.062980  \n","75%        51.897840       9.999465      85.838080       9.651235  \n","max      2833.608950     275.353660    7240.653730     600.766240  \n","\n","[8 rows x 90 columns]\n"]}],"source":["#print shape of dataset\n","print(\"Dataset shape:\",data.shape) #25175 row, 91 columns. We know that the label Y ('year) is the first one column.\n","\n","# saving data without first column 'year'\n","no_target_column_data = data[data.columns[1:]]\n","print(no_target_column_data.describe())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1707045399804,"user":{"displayName":"Andrea Bianchi","userId":"00641891010832459678"},"user_tz":-60},"id":"ODHp9i4rQo_s","outputId":"13836897-18c0-422a-aa2a-9e7dbbc81224"},"outputs":[],"source":["#Descrizione database\n","data.info() #Non ci sono valori mancanti e tutte le colonne dello stesso tipo (float64) ad eccezione della colonna 'Year' (int64)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1707045399804,"user":{"displayName":"Andrea Bianchi","userId":"00641891010832459678"},"user_tz":-60},"id":"t3Ti8y1Q5dmX"},"outputs":[],"source":["target_label = data[data.columns[:1]]"]},{"cell_type":"markdown","metadata":{"id":"2Uyb2s8SP6pk"},"source":["#### Data by target column 'Year'\n","\n","Sono presenti righe con categorie della colonna target 'Year' che vanno dal 1956 al 2009.\n","\n","C'è uno sbilanciamento del dataset, che presenta molte più righe (e per cui canzoni e features su cui verranno allenati i modelli) per gli anni dal (circa) 1990 in poi.\n","\n","Infatti, nel dataset per il 1990 stesso ci sono 3628 righe, per il 2000 ce ne sono più di 9mila e per il 2009 (anno maggiore == più vicino nel tempo all'anno odierno) ce ne sono più di 15mila.\n","In generale per gli anni 2000 ci sono circa più di 10mila righe, per gli altri, allontanandosi sempre più indietro nel tempo, ce ne sono sempre meno fino a toccare un minimodi circa 200 / 300.\n","\n","E' necessario bilanciare il dataset o comunque affidare dei pesi ad ogni categoria / classe in modo tale che il training sia bilanciato in base ai dati a nostra disposizione."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":517,"status":"ok","timestamp":1707045400319,"user":{"displayName":"Andrea Bianchi","userId":"00641891010832459678"},"user_tz":-60},"id":"S0H0xkU-P6pl","outputId":"92cdb4cd-7c1d-4028-b267-e4b896134e56"},"outputs":[{"name":"stdout","output_type":"stream","text":["Year\n","1956      283\n","1957      299\n","1958      291\n","1959      296\n","1960      212\n","1961      285\n","1962      302\n","1963      451\n","1964      473\n","1965      560\n","1966      689\n","1967      859\n","1968      934\n","1969     1105\n","1970     1174\n","1971     1065\n","1972     1144\n","1973     1298\n","1974     1092\n","1975     1241\n","1976     1089\n","1977     1251\n","1978     1463\n","1979     1554\n","1980     1551\n","1981     1581\n","1982     1798\n","1983     1693\n","1984     1684\n","1985     1789\n","1986     2110\n","1987     2561\n","1988     2805\n","1989     3335\n","1990     3628\n","1991     4323\n","1992     4771\n","1993     5263\n","1994     6061\n","1995     6629\n","1996     7065\n","1997     7591\n","1998     7907\n","1999     9119\n","2000     9642\n","2001    10795\n","2002    11726\n","2003    13691\n","2004    14803\n","2005    17476\n","2006    18767\n","2007    19702\n","2008    17380\n","2009    15519\n","Name: count, dtype: int64\n"]}],"source":["sorted_data_by_year = data.sort_values(by='Year')\n","\n","year_count = sorted_data_by_year['Year'].value_counts()\n","print(year_count.sort_index())"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12439,"status":"ok","timestamp":1707045412756,"user":{"displayName":"Andrea Bianchi","userId":"00641891010832459678"},"user_tz":-60},"id":"ng53auRRP6pl","outputId":"be7e535a-debf-4819-d722-942378f0d7ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["           S0                                                                   \n","        count       mean       std       min        25%        50%        75%   \n","Year                                                                            \n","1956    283.0  37.918317  6.360809  18.85936  34.160860  38.520610  42.777765  \\\n","1957    299.0  37.294501  6.540781  16.74940  33.014035  37.968080  42.231905   \n","1958    291.0  39.184471  5.760782  20.37114  35.591150  40.144380  43.481665   \n","1959    296.0  39.335948  5.538941  19.65088  35.905565  39.455235  43.312650   \n","1960    212.0  38.639910  5.091828  20.15428  35.462605  38.815100  42.417372   \n","1961    285.0  40.020702  5.230869  22.58792  36.956810  40.359160  43.613700   \n","1962    302.0  39.875598  5.279745  19.04782  36.942355  40.615420  43.641865   \n","1963    451.0  40.484300  5.043114  23.38250  37.397185  40.711390  44.273985   \n","1964    473.0  40.310878  6.289511  11.32260  36.386380  41.537300  44.805450   \n","1965    560.0  40.712386  5.614745  21.74910  37.218585  41.108940  44.760348   \n","1966    689.0  41.053348  5.659890  20.12509  37.533810  41.753400  44.966740   \n","1967    859.0  40.784786  5.273451  15.04494  37.759585  41.601670  44.491345   \n","1968    934.0  40.854622  4.956114  16.44924  38.108493  41.314615  44.126595   \n","1969   1105.0  40.652971  5.085214  16.73033  37.793860  41.231960  44.196980   \n","1970   1174.0  40.808433  5.074790  14.12235  37.764927  41.469720  44.489485   \n","1971   1065.0  40.421584  5.090619  20.77177  37.274020  40.962880  44.001620   \n","1972   1144.0  40.477185  5.351409  18.27024  37.436615  41.181235  44.228117   \n","1973   1298.0  40.860096  5.042862  19.87875  38.094755  41.385630  44.362215   \n","1974   1092.0  41.118869  5.341218  20.20474  38.321578  41.590060  44.882225   \n","1975   1241.0  41.316288  4.925764  21.70061  38.649110  41.805990  44.655950   \n","1976   1089.0  40.974346  5.150324  18.98493  38.075910  41.494960  44.590780   \n","1977   1251.0  42.101991  5.213205  17.82390  39.381395  42.692640  45.743705   \n","1978   1463.0  41.781486  5.643646  15.68058  38.519480  42.440010  45.896850   \n","1979   1554.0  42.238937  5.324317  18.56022  39.312695  42.812100  45.911113   \n","1980   1551.0  42.515740  5.239744  18.83214  39.588610  42.951660  46.304040   \n","1981   1581.0  42.145962  5.607586  18.07704  38.856480  42.734700  46.341260   \n","1982   1798.0  42.304766  5.367357  20.35233  39.047540  42.848400  46.058282   \n","1983   1693.0  42.037407  5.580528  13.85682  38.838590  42.697440  46.158510   \n","1984   1684.0  42.081753  5.744004  16.92865  39.010150  42.857510  46.019688   \n","1985   1789.0  42.478617  5.356552  19.32726  39.318490  42.936630  46.279440   \n","1986   2110.0  42.063249  5.950125  14.18859  38.656678  42.571045  46.255255   \n","1987   2561.0  41.651999  5.879643  18.97275  38.384680  42.359580  45.805320   \n","1988   2805.0  41.031874  5.877239  14.40601  37.829950  41.617120  44.895160   \n","1989   3335.0  41.372982  5.873242   6.69767  38.211760  41.896150  45.350810   \n","1990   3628.0  40.997901  5.929276   8.52542  37.673735  41.688300  45.044500   \n","1991   4323.0  40.924757  6.016520   6.19726  37.368375  41.813370  45.180375   \n","1992   4771.0  41.251873  6.022754  14.13498  37.744880  42.143750  45.605565   \n","1993   5263.0  41.291475  5.998125   4.83688  38.059875  42.035260  45.563830   \n","1994   6061.0  41.625470  5.984594   8.68787  38.409570  42.470960  45.837420   \n","1995   6629.0  42.006921  5.962930  13.49670  38.674290  42.901830  46.319830   \n","1996   7065.0  42.283225  5.946032  10.61508  39.022690  43.010990  46.562070   \n","1997   7591.0  42.843013  6.058029   7.19989  39.675190  43.731980  47.255835   \n","1998   7907.0  42.994995  6.169323   9.53274  39.713665  43.852970  47.493335   \n","1999   9119.0  43.403761  5.972494   4.95479  40.008065  44.263280  47.864425   \n","2000   9642.0  43.359562  6.189036   7.78896  40.035265  44.329805  47.832130   \n","2001  10795.0  43.589945  6.058795  12.28239  40.378355  44.588980  47.926895   \n","2002  11726.0  43.953905  6.209017   5.46576  40.753827  45.011025  48.450742   \n","2003  13691.0  44.038157  6.137352  11.27531  40.712560  45.106230  48.566410   \n","2004  14803.0  44.236801  5.924856   9.90657  41.074230  45.273110  48.614210   \n","2005  17476.0  44.448808  5.938885   6.83966  41.291713  45.444720  48.801640   \n","2006  18767.0  44.546591  5.953830   3.45526  41.372620  45.631330  48.928470   \n","2007  19702.0  44.886920  5.855651   8.13809  41.745427  46.045150  49.151543   \n","2008  17380.0  44.938865  5.824533   4.95544  41.911560  46.019090  49.130090   \n","2009  15519.0  45.116483  5.542387  11.01419  42.117295  46.071710  49.108445   \n","\n","                     S1             ...         S88                  S89   \n","           max    count       mean  ...         75%         max    count   \n","Year                                ...                                    \n","1956  49.54919    283.0 -36.746907  ...  118.785485  1065.09677    283.0  \\\n","1957  50.31424    299.0 -38.376579  ...  140.066915   675.10981    299.0   \n","1958  50.40543    291.0 -18.034811  ...  108.783270  6608.66057    291.0   \n","1959  51.07648    296.0 -21.209723  ...   56.224787   721.03993    296.0   \n","1960  48.64351    212.0 -17.572104  ...   57.633495   786.90325    212.0   \n","1961  51.31684    285.0 -26.710204  ...   71.472370  1181.89286    285.0   \n","1962  51.23267    302.0 -17.721863  ...  105.178755   876.03486    302.0   \n","1963  51.33622    451.0 -17.605829  ...  100.709025   548.08119    451.0   \n","1964  53.55105    473.0 -13.986682  ...   78.318420   826.67829    473.0   \n","1965  54.17324    560.0 -14.339154  ...   77.747995   551.04218    560.0   \n","1966  52.96672    689.0  -5.924311  ...   85.633950   888.86014    689.0   \n","1967  52.64639    859.0  -6.417906  ...   91.105860  1793.06522    859.0   \n","1968  55.54833    934.0  -7.110506  ...   84.050460   972.35896    934.0   \n","1969  52.21853   1105.0 -10.388956  ...  101.202770   659.48518   1105.0   \n","1970  52.01914   1174.0 -13.389502  ...   94.411383   981.56308   1174.0   \n","1971  53.16835   1065.0 -14.039262  ...   89.648620   869.05717   1065.0   \n","1972  52.93576   1144.0 -10.899264  ...   99.502713  1359.16280   1144.0   \n","1973  59.57970   1298.0  -8.847371  ...   91.593110  1086.19828   1298.0   \n","1974  53.00706   1092.0  -9.961630  ...   86.962847  1213.83893   1092.0   \n","1975  53.32363   1241.0  -5.532662  ...   81.098650  1047.37106   1241.0   \n","1976  54.33876   1089.0  -4.329017  ...   82.483220  1131.35213   1089.0   \n","1977  53.97449   1251.0   3.798493  ...   72.480150  1411.08063   1251.0   \n","1978  54.89080   1463.0   4.980759  ...   80.313955  1666.26857   1463.0   \n","1979  54.36339   1554.0  10.856379  ...   76.807592  1999.14344   1554.0   \n","1980  54.12734   1551.0  13.536916  ...   72.329320  1020.60371   1551.0   \n","1981  54.74852   1581.0  15.159614  ...   77.415930  2011.14956   1581.0   \n","1982  54.63285   1798.0  11.776439  ...   78.414905  2090.98647   1798.0   \n","1983  53.17396   1693.0  16.199605  ...   73.342660  1080.66384   1693.0   \n","1984  54.02483   1684.0  15.662226  ...   66.536957  1894.19767   1684.0   \n","1985  54.88745   1789.0  22.265959  ...   67.075440  1149.71308   1789.0   \n","1986  55.21019   2110.0  14.589776  ...   64.958745  1257.83074   2110.0   \n","1987  54.32857   2561.0   9.793209  ...   70.959090  1150.51740   2561.0   \n","1988  54.50149   2805.0  13.682053  ...   76.202220  1023.86809   2805.0   \n","1989  54.90116   3335.0  12.824598  ...   66.326205  1479.32460   3335.0   \n","1990  54.83938   3628.0   9.734392  ...   74.134682  1365.96212   3628.0   \n","1991  54.14422   4323.0   5.754883  ...   77.513655  1750.32096   4323.0   \n","1992  55.86278   4771.0   5.144943  ...   75.118515  1764.81920   4771.0   \n","1993  59.11796   5263.0   4.346653  ...   83.299985  4836.37828   5263.0   \n","1994  54.93215   6061.0   3.918173  ...   79.376510  1935.28626   6061.0   \n","1995  55.51187   6629.0   4.797228  ...   85.524950  2941.76201   6629.0   \n","1996  55.72039   7065.0   2.831914  ...   91.362500  2287.73518   7065.0   \n","1997  57.47548   7591.0   3.578401  ...   84.674780  3120.55200   7591.0   \n","1998  58.08253   7907.0   4.257383  ...   88.953350  3643.29973   7907.0   \n","1999  56.28748   9119.0   4.187755  ...   89.224515  2867.47985   9119.0   \n","2000  56.92077   9642.0   2.193343  ...   90.028058  3365.89931   9642.0   \n","2001  58.89497  10795.0   0.867491  ...   90.294020  3128.39889  10795.0   \n","2002  60.03401  11726.0   0.467808  ...   93.620047  2387.24328  11726.0   \n","2003  57.37422  13691.0  -1.869555  ...   93.271195  1922.33609  13691.0   \n","2004  55.97666  14803.0  -1.465929  ...   91.798550  7240.65373  14803.0   \n","2005  58.24420  17476.0  -0.935738  ...   86.748522  2881.36422  17476.0   \n","2006  59.53885  18767.0  -1.090703  ...   89.764830  4031.72811  18767.0   \n","2007  61.97014  19702.0  -0.078268  ...   86.640498  4166.94289  19702.0   \n","2008  61.49466  17380.0   0.049077  ...   84.224360  2687.46511  17380.0   \n","2009  60.83928  15519.0   0.682807  ...   89.427360  3079.03547  15519.0   \n","\n","                                                                       \n","          mean        std        min        25%       50%        75%   \n","Year                                                                   \n","1956  5.007813  20.499461  -62.96441  -5.192985  4.543730  16.330835  \\\n","1957  5.380798  21.016677  -58.59798  -5.311090  4.701690  14.605460   \n","1958  6.152983  33.817750  -50.49139  -5.783195  1.973620  13.191480   \n","1959  2.138063  16.253653  -44.33273  -6.180020  1.527430   8.673290   \n","1960  4.359508  21.187682 -101.96728  -7.207612  2.728620  14.894967   \n","1961  4.895144  19.413501 -104.45312  -4.410370  4.664390  14.445280   \n","1962  5.199076  17.738537  -43.53280  -4.912343  3.773775  13.203025   \n","1963  5.975124  17.084356  -91.45202  -2.534885  4.734580  14.299915   \n","1964  5.264140  17.196817  -54.01202  -4.662890  3.186270  12.604180   \n","1965  4.410483  17.771790  -56.00088  -5.255540  3.795560  14.143040   \n","1966  3.561131  18.329949  -88.62058  -6.137860  2.904990  11.744850   \n","1967  5.348428  18.446080  -60.80989  -4.940415  4.493800  14.022860   \n","1968  6.147886  20.472458  -99.97157  -4.573990  4.076620  14.312407   \n","1969  4.257621  19.832754  -82.87673  -5.894040  2.889980  12.279640   \n","1970  4.428209  18.032936  -68.89355  -4.827000  3.028845  12.833412   \n","1971  4.358221  21.576243  -76.78864  -5.736860  2.425180  12.574500   \n","1972  3.971229  22.560972  -81.09914  -7.592775  1.659530  13.595987   \n","1973  4.950717  19.005897  -61.55788  -5.274710  2.830050  13.178648   \n","1974  3.866598  19.597396 -110.97544  -6.249600  2.451180  12.385047   \n","1975  3.289034  18.288442  -95.11389  -5.711970  2.426070  11.996890   \n","1976  3.455883  19.715812  -53.05811  -7.292950  1.317800  11.435360   \n","1977  1.505066  19.268439 -129.22501  -7.185820  1.575520   9.967735   \n","1978  4.042081  18.114460  -81.34617  -5.536010  2.338600  11.845520   \n","1979  2.410795  20.142443 -100.52847  -7.126570  0.940565  10.200348   \n","1980  2.524275  17.104032  -98.26871  -5.727695  1.955390   9.610960   \n","1981  2.071444  20.031684 -109.91362  -6.775150  1.353840   9.656080   \n","1982  3.031048  17.967867  -65.12796  -5.937418  1.826005   9.589280   \n","1983  3.738284  18.641750 -135.70299  -5.032690  1.842620  10.448140   \n","1984  3.462921  18.947305  -87.33983  -5.757330  2.377865  11.050670   \n","1985  3.160717  18.260857  -58.33442  -5.858270  1.509040   9.885810   \n","1986  2.908754  20.581724 -103.12194  -5.899665  1.757355   9.946822   \n","1987  3.097694  17.869537 -154.73237  -5.182020  2.243550  10.397030   \n","1988  3.746985  19.448336 -208.77780  -5.886280  2.036130  11.050950   \n","1989  3.083658  19.088838 -116.92491  -5.664355  1.421180  10.250410   \n","1990  3.283777  20.107162 -172.76354  -6.402265  1.552410  10.572572   \n","1991  2.686050  20.276649 -239.99032  -7.131935  1.218670  10.355945   \n","1992  2.795116  20.276213 -143.06277  -6.930645  0.999920  10.558545   \n","1993  2.289115  21.371588 -255.68082  -7.365575  0.794640   9.594060   \n","1994  1.694285  20.520196 -193.00972  -7.753610  0.449470   9.851880   \n","1995  1.382425  22.170147 -177.81771  -8.459730  0.453420   9.967140   \n","1996  1.999850  22.190413 -148.80013  -8.298670  0.626680  10.404350   \n","1997  1.403958  22.845502 -140.46966  -8.886950  0.082620   9.617215   \n","1998  1.508273  22.839413 -151.06955  -8.764915  0.033770   9.930305   \n","1999  1.016721  22.481164 -278.02734  -9.229150 -0.244340   9.552185   \n","2000  0.534857  21.389825 -152.92049  -9.626705 -0.423050   9.168658   \n","2001  0.649310  22.611766 -148.88694  -9.814625 -0.538780   9.264410   \n","2002  1.210435  23.617429 -281.15060  -9.471263 -0.388415   9.703782   \n","2003  0.306863  23.074406 -133.85953 -10.381875 -0.788290   8.937875   \n","2004  0.824521  23.329780 -246.02706  -9.703995 -0.416070   9.296525   \n","2005  0.529361  23.513299 -235.30745 -10.292850 -0.879495   8.919638   \n","2006  0.103141  22.813737 -211.20544 -10.248670 -0.862790   8.688655   \n","2007  0.559032  22.967344 -171.95249  -9.737198 -0.885385   8.764112   \n","2008 -0.033780  22.476402 -286.03120 -10.119817 -0.995755   8.379317   \n","2009  0.470106  22.631435 -180.68953  -9.741320 -0.641750   8.844655   \n","\n","                 \n","            max  \n","Year             \n","1956   78.25363  \n","1957  169.30744  \n","1958  374.83052  \n","1959   78.66333  \n","1960   70.31322  \n","1961   80.99521  \n","1962  137.70116  \n","1963   93.93569  \n","1964   79.26990  \n","1965   89.10850  \n","1966   94.86038  \n","1967   96.06963  \n","1968  161.20629  \n","1969  117.38234  \n","1970   90.77915  \n","1971  146.05084  \n","1972  141.74644  \n","1973  117.21683  \n","1974  109.60130  \n","1975  119.43534  \n","1976  130.14788  \n","1977  124.37722  \n","1978  138.96775  \n","1979  265.77653  \n","1980   89.93077  \n","1981  239.24096  \n","1982  157.54666  \n","1983  134.55305  \n","1984  188.07151  \n","1985  202.02251  \n","1986  210.72183  \n","1987  138.54575  \n","1988  148.69411  \n","1989  224.38439  \n","1990  183.01514  \n","1991  163.54549  \n","1992  177.90777  \n","1993  187.92273  \n","1994  342.68251  \n","1995  255.05473  \n","1996  217.37658  \n","1997  600.76624  \n","1998  378.66214  \n","1999  210.39341  \n","2000  270.06075  \n","2001  306.09707  \n","2002  266.42670  \n","2003  289.31599  \n","2004  332.62108  \n","2005  371.31523  \n","2006  247.11685  \n","2007  358.71013  \n","2008  315.03052  \n","2009  316.51887  \n","\n","[54 rows x 720 columns]\n"]}],"source":["infos=sorted_data_by_year.groupby('Year')\n","print(infos.describe())"]},{"cell_type":"markdown","metadata":{"id":"3R2Oha0fP6pl"},"source":["---\n","#### Data visualization"]},{"cell_type":"markdown","metadata":{"id":"CFLjmhXYP6pl"},"source":["##### Density plot"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Funzione Density Plot/Histogramma per tutte le colonne del dataset\n","\n","def plot_density(dataset, columns_per_row=4, figsize=(15, 10)):\n","   \n","    num_columns =data.shape[1]\n","    num_rows = (num_columns - 1) // columns_per_row + 1\n","    \n","    fig, axes = plt.subplots(num_rows, columns_per_row, figsize=figsize)\n","    axes = axes.flatten()\n","    \n","    for i, column in enumerate(dataset.columns):\n","        ax = axes[i]\n","        ax.set_title(column)\n","        ax.hist(dataset[column], density=True, bins=30, alpha=0.5)\n","        dataset[column].plot(kind='kde', ax=ax, color='blue')\n","        \n","    for ax in axes[num_columns:]:\n","        ax.axis('off')  # Nasconde gli assi per le eventuali celle vuote\n","        \n","    plt.tight_layout()\n","    plt.show()\n","\n","# Utilizzo della funzione \n","plot_density(data.iloc[:,1:], columns_per_row=4, figsize=(55, 50))\n"]},{"cell_type":"markdown","metadata":{"id":"EMl2EzQ4hEXw"},"source":["Dal density plot notiamo come non sia presente una distribuzione gaussiana dei dati."]},{"cell_type":"markdown","metadata":{"id":"ybTHMPOrawZk"},"source":["##### Box plot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7K0Mg9FaazX8"},"outputs":[],"source":["# Box plot\n","plt.figure(figsize=(20, 8))\n","sns.boxplot(data=no_target_column_data, orient='v')  # orient='v' indica un boxplot verticale\n","\n","# Aggiunta di etichette all'asse x\n","plt.xticks(rotation=90)  # Puoi regolare l'angolo di inclinazione delle etichette per una migliore leggibilità\n","\n","# Titoli e etichette degli assi\n","plt.xlabel('Features')\n","plt.ylabel('Values')\n","\n","# Visualizzazione del boxplot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"chIlDJVJeJQS"},"outputs":[],"source":["# Box plot S0 to S12\n","plt.figure(figsize=(10, 12))\n","sns.boxplot(data=no_target_column_data.iloc[:,0:13], orient='v')  # orient='v' indica un boxplot verticale\n","\n","# Aggiunta di etichette all'asse x\n","plt.xticks(rotation=90)  # Puoi regolare l'angolo di inclinazione delle etichette per una migliore leggibilità\n","\n","# Titoli e etichette degli assi\n","plt.xlabel('Features')\n","plt.ylabel('Values')\n","\n","# Visualizzazione del boxplot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EKggpYUxesGG"},"outputs":[],"source":["# Box plot S13 to S23\n","plt.figure(figsize=(10, 15))\n","sns.boxplot(data=no_target_column_data.iloc[:,13:24], orient='v')  # orient='v' indica un boxplot verticale\n","\n","# Aggiunta di etichette all'asse x\n","plt.xticks(rotation=90)  # Puoi regolare l'angolo di inclinazione delle etichette per una migliore leggibilità\n","\n","# Titoli e etichette degli assi\n","plt.xlabel('Features')\n","plt.ylabel('Values')\n","\n","# Visualizzazione del boxplot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CE9tZH6UfTKf"},"outputs":[],"source":["# Box plot S24 to S34\n","plt.figure(figsize=(10, 17))\n","sns.boxplot(data=no_target_column_data.iloc[:,24:35], orient='v')  # orient='v' indica un boxplot verticale\n","\n","# Aggiunta di etichette all'asse x\n","plt.xticks(rotation=90)  # Puoi regolare l'angolo di inclinazione delle etichette per una migliore leggibilità\n","\n","# Titoli e etichette degli assi\n","plt.xlabel('Features')\n","plt.ylabel('Values')\n","\n","# Visualizzazione del boxplot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E2YKbhI6ft5G"},"outputs":[],"source":["# Box plot S35 to S45\n","plt.figure(figsize=(10, 17))\n","sns.boxplot(data=no_target_column_data.iloc[:,35:46], orient='v')  # orient='v' indica un boxplot verticale\n","\n","# Aggiunta di etichette all'asse x\n","plt.xticks(rotation=90)  # Puoi regolare l'angolo di inclinazione delle etichette per una migliore leggibilità\n","\n","# Titoli e etichette degli assi\n","plt.xlabel('Features')\n","plt.ylabel('Values')\n","\n","# Visualizzazione del boxplot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YsAasFt0f7I6"},"outputs":[],"source":["# Box plot S46 to S54\n","plt.figure(figsize=(10, 12))\n","sns.boxplot(data=no_target_column_data.iloc[:,46:55], orient='v')  # orient='v' indica un boxplot verticale\n","\n","# Aggiunta di etichette all'asse x\n","plt.xticks(rotation=90)  # Puoi regolare l'angolo di inclinazione delle etichette per una migliore leggibilità\n","\n","# Titoli e etichette degli assi\n","plt.xlabel('Features')\n","plt.ylabel('Values')\n","\n","# Visualizzazione del boxplot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"37dfDQhtgJbn"},"outputs":[],"source":["# Box plot S55 to S64\n","plt.figure(figsize=(10, 12))\n","sns.boxplot(data=no_target_column_data.iloc[:,55:65], orient='v')  # orient='v' indica un boxplot verticale\n","\n","# Aggiunta di etichette all'asse x\n","plt.xticks(rotation=90)  # Puoi regolare l'angolo di inclinazione delle etichette per una migliore leggibilità\n","\n","# Titoli e etichette degli assi\n","plt.xlabel('Features')\n","plt.ylabel('Values')\n","\n","# Visualizzazione del boxplot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GG5LrgyPgZmz"},"outputs":[],"source":["# Box plot S65 to S75\n","plt.figure(figsize=(10, 12))\n","sns.boxplot(data=no_target_column_data.iloc[:,65:76], orient='v')  # orient='v' indica un boxplot verticale\n","\n","# Aggiunta di etichette all'asse x\n","plt.xticks(rotation=90)  # Puoi regolare l'angolo di inclinazione delle etichette per una migliore leggibilità\n","\n","# Titoli e etichette degli assi\n","plt.xlabel('Features')\n","plt.ylabel('Values')\n","\n","# Visualizzazione del boxplot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"knfSWOvKgloB"},"outputs":[],"source":["# Box plot S76 to S82\n","plt.figure(figsize=(10, 12))\n","sns.boxplot(data=no_target_column_data.iloc[:,76:83], orient='v')  # orient='v' indica un boxplot verticale\n","\n","# Aggiunta di etichette all'asse x\n","plt.xticks(rotation=90)  # Puoi regolare l'angolo di inclinazione delle etichette per una migliore leggibilità\n","\n","# Titoli e etichette degli assi\n","plt.xlabel('Features')\n","plt.ylabel('Values')\n","\n","# Visualizzazione del boxplot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TZIWBsKTgw_B"},"outputs":[],"source":["# Box plot S83 to S89\n","plt.figure(figsize=(10, 12))\n","sns.boxplot(data=no_target_column_data.iloc[:,83:90], orient='v')  # orient='v' indica un boxplot verticale\n","\n","# Aggiunta di etichette all'asse x\n","plt.xticks(rotation=90)  # Puoi regolare l'angolo di inclinazione delle etichette per una migliore leggibilità\n","\n","# Titoli e etichette degli assi\n","plt.xlabel('Features')\n","plt.ylabel('Values')\n","\n","# Visualizzazione del boxplot\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"urGbkWGuijrP"},"source":["Nei **Boxplots** che abbiamo mostrato qua sopra, si possono notare come le features hanno una distribuzione di dati simile per quasi tutte le colonne, tranne per quelle che vanno da: *S0* a *S12*. Sono presenti, per ogni features, un gran numero di *outliers* sia sotto i valori minimi sia sopra i valori massimi del boxplot.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"hWSL4jcjTOqt"},"source":["##### Correlation Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ykb7kKnGelOG"},"outputs":[],"source":["# Calcolare la matrice di correlazione\n","correlation_matrix = no_target_column_data.corr()\n","\n","# Creare una heatmap della matrice di correlazione usando seaborn\n","plt.figure(figsize=(20, 20))\n","sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n","plt.title('Matrice di Correlazione')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ywbeCHw_eppy"},"outputs":[],"source":["# Eliminare i coefficienti di correlazione uguali a 1\n","correlation_matrix = correlation_matrix.mask(correlation_matrix == 1)\n","\n","# Estrarre le prime 20 coppie con i coefficienti di correlazione più alti\n","top_corr_pairs = correlation_matrix.unstack().nlargest(40)\n","\n","# Stampa i nomi delle colonne delle prime 20 coppie\n","print(\"Nomi delle colonne delle prime 20 coppie con coefficiente di correlazione più alto:\")\n","for (var1, var2), corr in top_corr_pairs.items():\n","    print(f\"{var1} e {var2}, Correlazione: {corr}\")\n","    print(f\"Nomi delle colonne: {var1}, {var2}\")\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"ORDv0HY1fYHm"},"source":["##### Correlation matrix su tutto il dataset\n","Data la correlation matrix riportata sopra abbiamo notato come vi sia una forte relazione tra le colonne da S12 a S24 circa, che sono caratterizzate da una forte presenza di valori outlier (lo abbiamo visto dai boxplot).\n","Dunque, proviamo anche a calcolare la correlation matrix escludendo queste colonne."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1T0E80xxTTec"},"outputs":[],"source":["subset_data = pd.concat([no_target_column_data.iloc[:,:12], no_target_column_data.iloc[:,24:]], axis=1)\n","\n","# Calcolare la matrice di correlazione\n","correlation_matrix = subset_data.corr()\n","\n","# Creare una heatmap della matrice di correlazione usando seaborn\n","plt.figure(figsize=(20, 20))\n","sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n","plt.title('Matrice di Correlazione')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t02N2YHdcfeR"},"outputs":[],"source":["# Eliminare i coefficienti di correlazione uguali a 1\n","correlation_matrix = correlation_matrix.mask(correlation_matrix == 1)\n","\n","# Estrarre le prime 20 coppie con i coefficienti di correlazione più alti\n","top_corr_pairs = correlation_matrix.unstack().nlargest(40)\n","\n","# Stampa i nomi delle colonne delle prime 20 coppie\n","print(\"Nomi delle colonne delle prime 20 coppie con coefficiente di correlazione più alto:\")\n","for (var1, var2), corr in top_corr_pairs.items():\n","    print(f\"{var1} e {var2}, Correlazione: {corr}\")\n","    print(f\"Nomi delle colonne: {var1}, {var2}\")\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"O_1F1yHEf-EB"},"source":["##### Correlation matrix (S12:S24 escluse)\n","In questa correlation matrix notiamo come i coefficienti di correlazione siano effettivamente più bassi, evidenziando il fatto che le variabili non sono correlate nello stesso modo in cui lo sono quelle dalla 12 alla 24.\n","\n","Dobbiamo dunque trattare gli outlier prima di poter stabilire quali variabili siano più rilevanti rispetto alle altre."]},{"cell_type":"markdown","metadata":{"id":"f8251ZnDg_1f"},"source":["##### Conclusioni dopo data visualization\n","Dal processo di visualizzazione dei dati deduciamo che è necessario trattare gli *outliers*: consideriamo quindi che non siano rilevanti per l'allenamento del nostro modello, ma si tratti di dati rumorosi e fuorvianti.\n","\n","In ogni caso valutare allenamento modelli con outliers.\n","\n","Valutare problema di **High Dimensionality**: tramite PCA (Princial Component Analysis) e LDA (Linear Discrimination Analysis)\n","\n","Valutare **Normalizzazione**: vedendo la distribuzione non gaussiana, opterei per **MinMaxScaling** (non escludere *Standardization*)"]},{"cell_type":"markdown","metadata":{"id":"KVQrvFND1L-T"},"source":["##### Trattamento outliers by winsorization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BQ9MZTQr4UYy"},"outputs":[],"source":["no_target_column_smoothed_data = pd.DataFrame(no_target_column_data.copy())\n","\n","def winsorize_column(column, k=1.5):\n","    q1 = column.quantile(0.25)\n","    q3 = column.quantile(0.75)\n","    iqr = q3 - q1\n","    lower_bound = q1 - k * iqr\n","    upper_bound = q3 + k * iqr\n","    column = np.where(column < lower_bound, lower_bound, column)\n","    column = np.where(column > upper_bound, upper_bound, column)\n","    return column\n","\n","for column in no_target_column_smoothed_data.columns:\n","  no_target_column_smoothed_data[column] = winsorize_column(no_target_column_smoothed_data[column])"]},{"cell_type":"markdown","metadata":{"id":"Urn-C0u3medk"},"source":["#### Z-SCORE (sostituzione outliers con MEDIAN) : MSE (post MinMaxScaling) : 41.132"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T4hVkc94medk"},"outputs":[],"source":["def replace_outliers_with_median(dataset, threshold=3):\n","    # Copia del dataset per evitare modifiche indesiderate\n","    cleaned_dataset = dataset.copy()\n","\n","    # Itera su ogni colonna/feature del dataset\n","    for column in cleaned_dataset.columns:\n","        # Calcola lo z-score per la feature corrente\n","        z_scores = np.abs(stats.zscore(cleaned_dataset[column]))\n","\n","        # Trova gli outliers superando la soglia\n","        outliers_indices = np.where(z_scores > threshold)[0]\n","\n","        # Sostituisci gli outliers con la mediana della colonna\n","        column_median = cleaned_dataset[column].median()\n","        cleaned_dataset[column].iloc[outliers_indices] = column_median\n","\n","    return cleaned_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9CNmTaMlmedk"},"outputs":[],"source":["# Sostituisci gli outliers con la media delle colonne\n","data_rmoutliers = replace_outliers_with_mean(data, 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F9oQxw1umedk"},"outputs":[],"source":["data_rmoutliers.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hpk5sMsGmedk"},"outputs":[],"source":["data_rmoutliers.isna().sum().sum() #Restituisce il Num totale dei valori NaN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hgivRGKRoWrc"},"outputs":[],"source":["X = no_target_column_smoothed_data[no_target_column_smoothed_data.columns[1:]]\n","y = no_target_column_smoothed_data[no_target_column_smoothed_data.columns[:1]]"]},{"cell_type":"markdown","metadata":{},"source":["#### Preprocessing: suddivisione del dataset"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1707045412757,"user":{"displayName":"Andrea Bianchi","userId":"00641891010832459678"},"user_tz":-60},"id":"jL4iGyM9medl"},"outputs":[],"source":["X=no_target_column_data.copy() #90 COLONNE\n","y=target_label.copy()"]},{"cell_type":"markdown","metadata":{"id":"PMcF-ajDmedl"},"source":["#### Splitting Dataset: Train & Validation"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1007,"status":"ok","timestamp":1707045413760,"user":{"displayName":"Andrea Bianchi","userId":"00641891010832459678"},"user_tz":-60},"id":"eDOVglhAmedl"},"outputs":[],"source":["# X sono le feature (variabili indipendenti), y è la colonna target\n","# 80% training set - 20% validation set\n","seed=89\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=seed,stratify=y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MBtR8tH32EdD"},"outputs":[],"source":["import numpy as np\n","\n","def find_nan_positions(data):\n","    nan_positions = np.argwhere(pd.isna(data).to_numpy())\n","    return nan_positions\n","\n","nan_positions = find_nan_positions(X_train)\n","\n","if nan_positions.size > 0:\n","    print(\"Valori NaN trovati alle seguenti posizioni:\")\n","    for position in nan_positions:\n","        print(f\"Riga: {position[0] + 1}, Colonna: {position[1] + 1}\")\n","else:\n","    print(\"Il DataFrame non contiene valori NaN.\")\n"]},{"cell_type":"markdown","metadata":{"id":"uTcCfII4P6pl"},"source":["---\n","#### Data Preprocessing (LR)\n"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1707045413761,"user":{"displayName":"Andrea Bianchi","userId":"00641891010832459678"},"user_tz":-60},"id":"j6JKD8MOQo_z"},"outputs":[],"source":["X = X_train.copy()\n","y = y_val.copy()"]},{"cell_type":"markdown","metadata":{"id":"xyj2FjYUpXJD"},"source":["##### Boxplot after outliers' smoothing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vLWuw2-H6PDT"},"outputs":[],"source":["# Box plot\n","plt.figure(figsize=(20, 8))\n","sns.boxplot(data=X, orient='v')  # orient='v' indica un boxplot verticale\n","\n","# Aggiunta di etichette all'asse x\n","plt.xticks(rotation=90)  # Puoi regolare l'angolo di inclinazione delle etichette per una migliore leggibilità\n","\n","# Titoli e etichette degli assi\n","plt.xlabel('Features')\n","plt.ylabel('Values')\n","\n","# Visualizzazione del boxplot\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["#### Undersampling e Oversampling (non migliora MSE) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from collections import Counter\n","from imblearn.under_sampling import ClusterCentroids\n","from imblearn.over_sampling import SMOTE\n","\n","def downSampling(x_train,y_train):\n","    # Controlla la distribuzione delle classi prima del downsampling\n","    print(\"Distribuzione delle classi prima del downsampling:\")\n","    print(Counter(y_train['Year']))\n","\n","    cc = ClusterCentroids(random_state=seed,)\n","\n","    # Effettua il downsampling\n","    X_resampled, y_resampled = cc.fit_resample(X, y_train['Year'])\n","\n","    return X_resampled,y_resampled\n","\n","def upSampling(x_train,y_train):\n","    X_resampled, y_resampled = SMOTE().fit_resample(x_train, y_train['Year'])\n","    return X_resampled,y_resampled\n","\n","\n","x_resempled,y_resampled= upSampling(X_train,y_train)\n"]},{"cell_type":"markdown","metadata":{"id":"fmcYCSwj1Jk7"},"source":["##### Min max scaling"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":639,"status":"ok","timestamp":1707045414398,"user":{"displayName":"Andrea Bianchi","userId":"00641891010832459678"},"user_tz":-60},"id":"A3Pa8l4qP6pm","outputId":"618d0728-f069-470e-9464-c674ed67c4ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Dati di training normalizzati MinMaxScaling:\n","[[0.60871594 0.53356923 0.4494677  ... 0.53845299 0.51108995 0.35777756]\n"," [0.56156007 0.50000065 0.67651561 ... 0.47862945 0.52086774 0.37412128]\n"," [0.7086659  0.56483163 0.51686467 ... 0.49568095 0.50430072 0.33343394]\n"," ...\n"," [0.62054814 0.41932825 0.42143407 ... 0.50094978 0.51898317 0.34341102]\n"," [0.76981599 0.53818665 0.51157919 ... 0.49243993 0.50699643 0.31996933]\n"," [0.54791055 0.34766547 0.56625569 ... 0.54115006 0.50531332 0.40491751]]\n"]}],"source":["X_Validation = X_val.copy()\n","\n","# Min-Max Scaling\n","# Creazione dell'oggetto MinMaxScaler e adattamento solo al training set\n","#file = open(\"scaler.save\",\"wb\") #salvataggio dello scaler sul disco nel file \"scaler.save\"\n","scaler = MinMaxScaler()\n","X_scaled = scaler.fit_transform(X)\n","#apply transform on validation set\n","X_val_scaled = scaler.transform(X_Validation)\n","#pickle.dump(scaler, file)\n","#file.close()\n","\n","#name columns after min-max scaling\n","# num_colonne = X_scaled.shape[1]  # Ottieni il numero di colonne\n","# nome_colonne = ['S' + str(i) for i in range(num_colonne)]\n","# X_scaled_df = pd.DataFrame(X_scaled, columns=nome_colonne)\n","\n","# print(\"Dati di training originali:\")\n","# print(X)\n","print(\"\\nDati di training normalizzati MinMaxScaling:\")\n","print(X_scaled)\n","# print(\"\\nDati di validation originali:\")\n","# print(X_Validation)\n","# print(\"\\nDati di validation normalizzati Min-Max:\")\n","# print(X_val_scaled)"]},{"cell_type":"markdown","metadata":{},"source":["#### Standardization"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# standardization of dependent variables\n","scaler=StandardScaler()\n","#standardization x_train\n","X_std = scaler.fit_transform(X) \n","#apply transform on validation set\n","X_val_std = scaler.transform(X_Validation)"]},{"cell_type":"markdown","metadata":{"id":"XHINVUkdtJoM"},"source":["##### Boxplot after min max scaling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ma3js70ltI8T"},"outputs":[],"source":["# Box plot\n","plt.figure(figsize=(20, 8))\n","sns.boxplot(data=X_scaled, orient='v')  # orient='v' indica un boxplot verticale\n","\n","# Aggiunta di etichette all'asse x\n","plt.xticks(rotation=90)  # Puoi regolare l'angolo di inclinazione delle etichette per una migliore leggibilità\n","\n","# Titoli e etichette degli assi\n","plt.xlabel('Features')\n","plt.ylabel('Values')\n","\n","# Visualizzazione del boxplot\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"kbpicgLythdx"},"source":["##### Density plot after min max scaling"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m08SIjcZth1M"},"outputs":[],"source":["# Density plot\n","fig, axs = plt.subplots(15, 3, figsize=(15, 60))\n","counter = 0\n","\n","for i in range(15):\n","  for j in range(3):\n","\n","    # Plot KDE\n","    sns.kdeplot(X_scaled[:,counter], ax=axs[i, j], color='g', bw_adjust=2, label='Smooth factor=2')\n","\n","    # Plot CDF\n","    sns.kdeplot(X_scaled[:,counter], ax=axs[i, j], color='r', cumulative=True, label='CDF')\n","\n","    axs[i, j].set_xlabel(\"S\" + str(counter))\n","    counter = counter+1\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"UD7f8EvjuYhC"},"source":["##### PCA"]},{"cell_type":"markdown","metadata":{"id":"4eTmKxDCR2yT"},"source":["##### Studio n_components"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"27Up3XRC5zTq"},"outputs":[],"source":["num_columns = X_scaled.shape[1]\n","nums = np.arange(num_columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iFVYY53W51QW"},"outputs":[],"source":["var_ratio = []\n","for num in nums:\n","  pca = PCA(n_components=num)\n","  pca.fit(X_scaled)\n","  var_ratio.append(np.sum(pca.explained_variance_ratio_))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"piiImA2I55Te"},"outputs":[],"source":["#Dalla Figura si nota come la linea di cutoff del 95% interseca il valore della X nella colonna 51/52\n","plt.figure(figsize=(30,4),dpi=150)\n","plt.grid()\n","plt.plot(nums,var_ratio,marker='o')\n","plt.xlabel('n_components')\n","plt.xticks(np.arange(0,90,1))\n","plt.ylabel('Explained variance ratio')\n","plt.title('n_components vs. Explained Variance Ratio')\n","#linea di cutoff del 95%\n","plt.axhline(y=0.95, color='r', linestyle='-')\n","plt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)"]},{"cell_type":"markdown","metadata":{"id":"-yJuKNav7NcA"},"source":["##### PCA Analysis"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"EqsS0jpMowDa"},"outputs":[],"source":["# Inizializzare l'oggetto PCA\n","pca = PCA(n_components=60) #52\n","X_decomposed = pca.fit_transform(X_scaled)\n","#pca.get_feature_names_out(X_scaled_df.columns)\n","\n","# Ottieni i vettori delle componenti principali\n","components = pca.components_\n","\n","#validation data after PCA\n","X_val_decomposed = pca.transform(X_val_scaled)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Scree Plot -> mostra la percentuale di variazione spiegata da ogni componente principale\n","PC_values = np.arange(pca.n_components_) + 1\n","plt.figure(figsize=(10,10))\n","plt.grid()\n","plt.plot(PC_values, pca.explained_variance_ratio_, 'o-', linewidth=2, color='blue')\n","plt.title('Scree Plot')\n","plt.xlabel('Principal Component')\n","plt.xticks(range(0,90,2))\n","plt.ylabel('Variance Explained')\n","plt.show()\n","print(\"Explainer variance of each component:\",pca.explained_variance_ratio_)\n","print(\"Variance total:\", sum(pca.explained_variance_ratio_))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_columns=X_decomposed.shape[1]"]},{"cell_type":"markdown","metadata":{"id":"S2JIWRU7vV6t"},"source":["##### Boxplot after PCA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HYVDPb0kvTor"},"outputs":[],"source":["# Box plot\n","plt.figure(figsize=(20, 8))\n","sns.boxplot(data=X_decomposed, orient='v')  # orient='v' indica un boxplot verticale\n","\n","# Aggiunta di etichette all'asse x\n","plt.xticks(rotation=90)  # Puoi regolare l'angolo di inclinazione delle etichette per una migliore leggibilità\n","\n","# Titoli e etichette degli assi\n","plt.xlabel('Features')\n","plt.ylabel('Values')\n","\n","# Visualizzazione del boxplot\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Z-4WZ8iq9Vbj"},"source":["#### Regressione Lineare"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3307,"status":"ok","timestamp":1707045417703,"user":{"displayName":"Andrea Bianchi","userId":"00641891010832459678"},"user_tz":-60},"id":"fIXG6smx9M4a","outputId":"e8f922ac-7b84-4875-f814-7c9cd57deb13"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean squared error: 84.343\n","MAE: 6.603\n","MAPE: 0.003\n","R2: 0.235\n"]}],"source":["##MinMaxScaling(), MSE: 84.500\n","##MinMaxScaling(),PCA, MSE:86.114\n","\n","regr = LinearRegression()\n","\n","# Train the model using the training sets\n","regr.fit(X_scaled, y_train)\n","\n","#file = open(\"Lregression.save\",\"wb\")\n","#pickle.dump(regr, file)\n","#file.close()\n","\n","# Make predictions using the testing set\n","y_predictions = regr.predict(X_val_scaled)\n","#MSE\n","mse = mean_squared_error(y_val, y_predictions)\n","#MAE\n","mae = mean_absolute_error(y_val, y_predictions)\n","#MAPE\n","mape = mean_absolute_percentage_error(y_val, y_predictions)\n","#R2\n","r2 = r2_score(y_val, y_predictions)\n","\n","print(\"Mean squared error: %.3f\" % mse)\n","print(\"MAE: %.3f\" % mae)\n","print(\"MAPE: %.3f\" % mape)\n","print(\"R2: %.3f\" % r2)"]},{"cell_type":"markdown","metadata":{"id":"xPRgKpYEmedr"},"source":["#### Random Forest Regressor con GridSearch"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Definire la grid e la metrica di valutazione\n","grid1 = {\n","    'max_depth': [200,300],\n","    # 'max_features': [3],\n","    # 'min_samples_leaf': [2],\n","    # 'min_samples_split': [3],\n","    'n_estimators': [300,500,1000]\n","}\n","\n","# Creare la scorning function\n","scoring = make_scorer(mean_squared_error, greater_is_better=False)\n","\n","# Grid Search function\n","CV_rfr = GridSearchCV(estimator=RandomForestRegressor(), param_grid=grid1, cv=5, \n","                      scoring=\"neg_mean_squared_error\",n_jobs=-1,verbose=2)\n","\n","# Modificare la forma del target y\n","y_train_reshaped = np.ravel(y_train)\n","\n","CV_rfr.fit(X_scaled, y_train_reshaped)\n","\n","predictions = CV_rfr.predict(X_val_scaled)\n","mse = mean_squared_error(y_val, predictions)\n","\n","# Print results\n","print(\"----------BEST PARAMS----------\")\n","print(CV_rfr.best_params_)\n","print(\"--------------------------------\")\n","print(\"Mean squared error: %.3f\" % mse)\n","\n","#-------------MINMAXSCALING (CON PCA=80)------------------\n","#----------BEST PARAMS----------\n","#{'max_depth': 4, 'n_estimators': 300, 'random_state': 89}\n","#Mean squared error: 93.907\n","#-------------MINMAXSCALING (CON PCA=52)------------------\n","# ----------BEST PARAMS----------\n","# {'max_depth': 4, 'n_estimators': 1000, 'random_state': 89}\n","# --------------------------------\n","\n","#-----------Solo MinMaxScaling------------------\n","# Mean squared error: 93.910\n","# ----------BEST PARAMS----------\n","# {'max_depth': 90, 'max_features': 3, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 300}\n","# --------------------------------\n","# Mean squared error: 84.530\n","# ----------BEST PARAMS----------\n","# {'max_depth': 200, 'max_features': 3, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 300}\n","# --------------------------------\n","# Mean squared error: 84.378"]},{"cell_type":"markdown","metadata":{"id":"Ad8_aIvGmedr"},"source":["#### KNN con GridSearch (Provare con Dati Normalizzati, Rimuovendo Outliers e PCA)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DELLRnrMmedr"},"outputs":[],"source":["# Definisci i parametri da testare\n","# param_grid = {'n_neighbors': [3, 5, 7, 9, 11]} vecchia iterazione\n","param_grid = {'n_neighbors': list(range(25, 60)), \"weights\": [\"uniform\",\"distance\"],\"n_jobs\":[-1]} #-1 means using all processors.\n","\n","# Crea un'istanza del modello KNN per la regressione\n","knn_regressor = KNeighborsRegressor()\n","y_train_new = np.ravel(y_train)\n","\n","# Crea un'istanza di GridSearchCV per trovare il miglior parametro\n","grid_search = GridSearchCV(knn_regressor, param_grid, cv=5, scoring='neg_mean_squared_error')\n","\n","# Esegui la ricerca dei parametri utilizzando il set di addestramento\n","grid_search.fit(X_scaled, y_train_new)\n","\n","# Ottieni il miglior parametro trovato\n","best_k = grid_search.best_params_['n_neighbors']\n","best_weight = grid_search.best_params_['weights']\n","\n","# Utilizza il modello addestrato con il miglior parametro per fare previsioni su nuovi dati\n","best_knn_regressor = grid_search.best_estimator_\n","y_predictions = best_knn_regressor.predict(X_val_scaled)\n","\n","# scores = []\n","# for i in range(1,100):\n","#     knn = KNeighborsRegressor(n_neighbors=i)\n","#     knn.fit(X_scaled,y_train_new)\n","#     y_pred = knn.predict(X_val_scaled)\n","#     scores.append(accuracy_score(y_val, y_pred))\n","\n","# plt.plot(range(1,16),scores)\n","\n","# Calcola le metriche di valutazione\n","mse = mean_squared_error(y_val, y_predictions)\n","rmse = np.sqrt(mse)\n","r2 = r2_score(y_val, y_predictions)\n","mae = mean_absolute_error(y_val, y_predictions)\n","#MAPE\n","mape = mean_absolute_percentage_error(y_val, y_predictions)\n","\n","print(\"Miglior parametro K:\", best_k, \"weights:\",best_weight)\n","print(\"MSE:\", mse)\n","print(\"RMSE:\", rmse)\n","print(\"R2 Score:\", r2)\n","print(\"MAE:\", mae)\n","print(\"MAPE: %.3f\" % mape)\n","# BEST PARAMS\n","# Miglior parametro K: 28 weights: distance\n","# MSE: 76.07494414444997"]},{"cell_type":"markdown","metadata":{"id":"vQPKRyA5medr"},"source":["#### SVM Regressor"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"tKm670Zqmeds"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[25], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Ricerca Grid per il tuning degli iperparametri e dei kernel\u001b[39;00m\n\u001b[0;32m     14\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39msvr_model, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_decomposed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_new\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Valutazione del modello migliore\u001b[39;00m\n\u001b[0;32m     18\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1853\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1854\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1860\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1861\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1862\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\joblib\\parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1784\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 732\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[1;32m--> 250\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n","File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\svm\\_base.py:329\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    315\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[0;32m    319\u001b[0m (\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[0;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[1;32m--> 329\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# TODO(1.4): Replace \"_class_weight\" with \"class_weight_\"\u001b[39;49;00m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_class_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n","File \u001b[1;32msklearn\\svm\\_libsvm.pyx:265\u001b[0m, in \u001b[0;36msklearn.svm._libsvm.fit\u001b[1;34m()\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Definizione della griglia di iperparametri e kernel\n","param_grid = {\n","    'C': [0.1, 1],\n","    'epsilon': [0.01, 0.1, 1],\n","    'kernel': ['linear', 'rbf', 'poly']\n","}\n","\n","y_train_new = np.ravel(y_train)\n","\n","# Creazione del modello SVR\n","svr_model = SVR()\n","\n","# Ricerca Grid per il tuning degli iperparametri e dei kernel\n","grid_search = GridSearchCV(estimator=svr_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error',n_jobs=-1)\n","grid_search.fit(X_decomposed, y_train_new)\n","\n","# Valutazione del modello migliore\n","best_model = grid_search.best_estimator_\n","y_predictions = best_model.predict(X_val_decomposed)\n","\n","# Calcola MSE\n","mse = mean_squared_error(y_val, y_predictions)\n","# Calcola RMSE\n","rmse = np.sqrt(mse)\n","# Calcola R2 Score\n","r2 = r2_score(y_val, y_predictions)\n","# Calcola MAE\n","mae = mean_absolute_error(y_val, y_predictions)\n","# Calcola MAPE\n","mape = mean_absolute_percentage_error(y_val,y_predictions)\n","\n","print(\"Best parameters:\", grid_search.best_params_)\n","print(\"MSE:\", mse)\n","print(\"RMSE:\", rmse)\n","print(\"R2 Score:\", r2)\n","print(\"MAE:\", mae)\n","print(\"MAPE:\", mape)"]},{"cell_type":"markdown","metadata":{},"source":["#### FF (Feed-Forward) reti neurali (Gabri)"]},{"cell_type":"markdown","metadata":{},"source":["### Tab Net Neural Network"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">06</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:22:56</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">834</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">140</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n","</pre>\n"],"text/plain":["\u001b[1;36m2024\u001b[0m-\u001b[1;36m06\u001b[0m-\u001b[1;36m07\u001b[0m \u001b[1;92m10:22:56\u001b[0m,\u001b[1;36m834\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m140\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"]},"metadata":{},"output_type":"display_data"}],"source":["from pytorch_tabular import TabularModel\n","from pytorch_tabular.models import TabNetModelConfig  # Importa TabNet\n","from pytorch_tabular.config import (\n","    DataConfig,\n","    OptimizerConfig,\n","    TrainerConfig,\n",")\n","\n","# `num_col_names` lista con i nomi delle 89 colonne numeriche\n","num_col_names =no_target_column_data.columns.tolist()\n","\n","\n","# MinMaxScaling e creazione DataFrame per train e validation\n","train = pd.DataFrame(X_scaled, columns=no_target_column_data.columns)\n","train['Year'] = y_train.values\n","\n","val = pd.DataFrame(X_val_scaled, columns=no_target_column_data.columns)\n","val['Year'] = y_val.values\n","\n","# Configurazione dei dati\n","data_config = DataConfig(\n","    target=[\"Year\"],  # Target deve essere una lista\n","    continuous_cols=num_col_names,\n","    categorical_cols=[],  # Nessuna colonna categoriale\n",")\n","\n","# Configurazione del trainer\n","trainer_config = TrainerConfig(\n","    auto_lr_find=True,  # Trova automaticamente il learning rate\n","    batch_size=1024,\n","    max_epochs=100,\n","    seed=seed\n",")\n","\n","# Configurazione dell'ottimizzatore\n","optimizer_config = OptimizerConfig()\n","\n","# Configurazione del modello TabNet per la regressione\n","model_config = TabNetModelConfig(\n","    task=\"regression\",\n","    n_d=64,  # Dimensioni delle feature embeddings per il decoder\n","    n_a=64,  # Dimensioni delle feature embeddings per l'attenzione\n","    n_steps=5,  # Numero di decision steps\n","    gamma=1.5,  # Coefficiente per il modulo attuale delle feature\n","    n_independent=2,  # Numero di layer completamente connessi indipendenti\n","    n_shared=2,  # Numero di layer completamente connessi condivisi\n","    learning_rate=1e-3,\n","    seed=seed\n",")\n","\n","tabular_model = TabularModel(\n","    data_config=data_config,\n","    model_config=model_config,\n","    optimizer_config=optimizer_config,\n","    trainer_config=trainer_config,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Supponiamo che `train` e `val` siano i tuoi DataFrames di training e validation\n","tabular_model.fit(train=train, validation=val,seed=seed)\n","\n","# Valutare il modello\n","result = tabular_model.evaluate(val)\n","print(result)\n","\n","# Fare predizioni\n","pred_df = tabular_model.predict(val)\n","print(pred_df)\n","\n","y_true_val=val['Year']\n","y_pred_val=pred_df['Year']\n","\n","mse=mean_squared_error(y_true_val,y_pred_val)\n","mae=mean_absolute_error(y_true_val,y_pred_val)\n","mape=mean_absolute_percentage_error(y_true_val,y_pred_val)\n","r2score=r2_score(y_true_val,y_pred_val)\n","print(\"MSE: \",mse,\" MAE:\",mae,\" MAPE:\",mape,\" R2_SCORE:\",r2score)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Salvare e caricare il modello\n","tabular_model.save_model(\"examples/tabnet_model\")\n","loaded_model = TabularModel.load_model(\"examples/tabnet_model\")"]},{"cell_type":"markdown","metadata":{"id":"x32tm4z0P6pm"},"source":["---\n","#### Data Modeling (tuning hyperparams)\n"]},{"cell_type":"markdown","metadata":{"id":"ZkqVSnQNme08"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"13EL3lKAP6pm"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"U5yOvc9KP6pm"},"source":["---\n","#### Performance Evaluation\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["CFLjmhXYP6pl","ybTHMPOrawZk","hWSL4jcjTOqt","ORDv0HY1fYHm","KVQrvFND1L-T","CXfYu38cmedi","Bl1WypSsmedj","Urn-C0u3medk","xyj2FjYUpXJD","XHINVUkdtJoM","kbpicgLythdx","4eTmKxDCR2yT","-yJuKNav7NcA","S2JIWRU7vV6t"],"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
